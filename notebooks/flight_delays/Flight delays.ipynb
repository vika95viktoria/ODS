{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from matplotlib.pyplot import figure\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelBinarizer\n",
    "from xgboost import XGBClassifier\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "from category_encoders import TargetEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'flight-delays-spring-2018/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(DATA_PATH + \"flight_delays_train.csv\")\n",
    "test = pd.read_csv(DATA_PATH + \"flight_delays_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>DayofMonth</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>DepTime</th>\n",
       "      <th>UniqueCarrier</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Dest</th>\n",
       "      <th>Distance</th>\n",
       "      <th>dep_delayed_15min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c-8</td>\n",
       "      <td>c-21</td>\n",
       "      <td>c-7</td>\n",
       "      <td>1934</td>\n",
       "      <td>AA</td>\n",
       "      <td>ATL</td>\n",
       "      <td>DFW</td>\n",
       "      <td>732</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c-4</td>\n",
       "      <td>c-20</td>\n",
       "      <td>c-3</td>\n",
       "      <td>1548</td>\n",
       "      <td>US</td>\n",
       "      <td>PIT</td>\n",
       "      <td>MCO</td>\n",
       "      <td>834</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c-9</td>\n",
       "      <td>c-2</td>\n",
       "      <td>c-5</td>\n",
       "      <td>1422</td>\n",
       "      <td>XE</td>\n",
       "      <td>RDU</td>\n",
       "      <td>CLE</td>\n",
       "      <td>416</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c-11</td>\n",
       "      <td>c-25</td>\n",
       "      <td>c-6</td>\n",
       "      <td>1015</td>\n",
       "      <td>OO</td>\n",
       "      <td>DEN</td>\n",
       "      <td>MEM</td>\n",
       "      <td>872</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c-10</td>\n",
       "      <td>c-7</td>\n",
       "      <td>c-6</td>\n",
       "      <td>1828</td>\n",
       "      <td>WN</td>\n",
       "      <td>MDW</td>\n",
       "      <td>OMA</td>\n",
       "      <td>423</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Month DayofMonth DayOfWeek  DepTime UniqueCarrier Origin Dest  Distance  \\\n",
       "0   c-8       c-21       c-7     1934            AA    ATL  DFW       732   \n",
       "1   c-4       c-20       c-3     1548            US    PIT  MCO       834   \n",
       "2   c-9        c-2       c-5     1422            XE    RDU  CLE       416   \n",
       "3  c-11       c-25       c-6     1015            OO    DEN  MEM       872   \n",
       "4  c-10        c-7       c-6     1828            WN    MDW  OMA       423   \n",
       "\n",
       "  dep_delayed_15min  \n",
       "0                 N  \n",
       "1                 N  \n",
       "2                 N  \n",
       "3                 N  \n",
       "4                 Y  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['c-7', 'c-3', 'c-5', 'c-6', 'c-4', 'c-2', 'c-1'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['DayOfWeek'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1728x864 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "delayed_flights = train[train['dep_delayed_15min'] == 'Y']\n",
    "\n",
    "sns.set(rc={\"figure.figsize\": (24, 12)})\n",
    "ax = sns.countplot(delayed_flights['DayOfWeek'])\n",
    "plt.xlabel('Day of Week', fontsize=20);\n",
    "plt.ylabel('Distribution', fontsize=20);\n",
    "plt.tick_params(axis='both', which='major', labelsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1728x864 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(rc={\"figure.figsize\": (24, 12)})\n",
    "ax = sns.countplot(delayed_flights['Month'])\n",
    "plt.xlabel('Month', fontsize=20);\n",
    "plt.ylabel('Distribution', fontsize=20);\n",
    "plt.tick_params(axis='both', which='major', labelsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1728x864 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(rc={\"figure.figsize\": (24, 12)})\n",
    "ax = sns.countplot(delayed_flights['DayofMonth'])\n",
    "plt.xlabel('Day of Month', fontsize=20);\n",
    "plt.ylabel('Distribution', fontsize=20);\n",
    "plt.tick_params(axis='both', which='major', labelsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_data = train.pivot_table(index=['Month', 'DayofMonth', 'DayOfWeek'],\n",
    "                  columns='dep_delayed_15min', aggfunc='size', fill_value=0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_data['ratio'] = agg_data.apply(lambda x: float(x['Y']) / (x['N'] + x['Y']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>dep_delayed_15min</th>\n",
       "      <th>Month</th>\n",
       "      <th>DayofMonth</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>N</th>\n",
       "      <th>Y</th>\n",
       "      <th>ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>c-8</td>\n",
       "      <td>c-10</td>\n",
       "      <td>c-4</td>\n",
       "      <td>65</td>\n",
       "      <td>75</td>\n",
       "      <td>0.535714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>c-12</td>\n",
       "      <td>c-22</td>\n",
       "      <td>c-5</td>\n",
       "      <td>75</td>\n",
       "      <td>77</td>\n",
       "      <td>0.506579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>c-1</td>\n",
       "      <td>c-2</td>\n",
       "      <td>c-1</td>\n",
       "      <td>66</td>\n",
       "      <td>60</td>\n",
       "      <td>0.476190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>c-10</td>\n",
       "      <td>c-27</td>\n",
       "      <td>c-5</td>\n",
       "      <td>76</td>\n",
       "      <td>66</td>\n",
       "      <td>0.464789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>c-12</td>\n",
       "      <td>c-23</td>\n",
       "      <td>c-6</td>\n",
       "      <td>71</td>\n",
       "      <td>56</td>\n",
       "      <td>0.440945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>c-12</td>\n",
       "      <td>c-16</td>\n",
       "      <td>c-5</td>\n",
       "      <td>75</td>\n",
       "      <td>59</td>\n",
       "      <td>0.440299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>c-6</td>\n",
       "      <td>c-26</td>\n",
       "      <td>c-1</td>\n",
       "      <td>69</td>\n",
       "      <td>53</td>\n",
       "      <td>0.434426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>c-12</td>\n",
       "      <td>c-15</td>\n",
       "      <td>c-5</td>\n",
       "      <td>95</td>\n",
       "      <td>67</td>\n",
       "      <td>0.413580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>c-2</td>\n",
       "      <td>c-18</td>\n",
       "      <td>c-6</td>\n",
       "      <td>74</td>\n",
       "      <td>51</td>\n",
       "      <td>0.408000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>c-7</td>\n",
       "      <td>c-21</td>\n",
       "      <td>c-5</td>\n",
       "      <td>86</td>\n",
       "      <td>57</td>\n",
       "      <td>0.398601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>c-12</td>\n",
       "      <td>c-15</td>\n",
       "      <td>c-4</td>\n",
       "      <td>78</td>\n",
       "      <td>51</td>\n",
       "      <td>0.395349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>c-6</td>\n",
       "      <td>c-27</td>\n",
       "      <td>c-2</td>\n",
       "      <td>82</td>\n",
       "      <td>53</td>\n",
       "      <td>0.392593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>c-6</td>\n",
       "      <td>c-24</td>\n",
       "      <td>c-6</td>\n",
       "      <td>77</td>\n",
       "      <td>49</td>\n",
       "      <td>0.388889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>c-1</td>\n",
       "      <td>c-3</td>\n",
       "      <td>c-2</td>\n",
       "      <td>88</td>\n",
       "      <td>56</td>\n",
       "      <td>0.388889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>c-7</td>\n",
       "      <td>c-1</td>\n",
       "      <td>c-5</td>\n",
       "      <td>98</td>\n",
       "      <td>62</td>\n",
       "      <td>0.387500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>c-12</td>\n",
       "      <td>c-9</td>\n",
       "      <td>c-5</td>\n",
       "      <td>86</td>\n",
       "      <td>54</td>\n",
       "      <td>0.385714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>c-1</td>\n",
       "      <td>c-3</td>\n",
       "      <td>c-1</td>\n",
       "      <td>84</td>\n",
       "      <td>52</td>\n",
       "      <td>0.382353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>c-11</td>\n",
       "      <td>c-28</td>\n",
       "      <td>c-1</td>\n",
       "      <td>97</td>\n",
       "      <td>57</td>\n",
       "      <td>0.370130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>c-1</td>\n",
       "      <td>c-5</td>\n",
       "      <td>c-3</td>\n",
       "      <td>80</td>\n",
       "      <td>47</td>\n",
       "      <td>0.370079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>c-8</td>\n",
       "      <td>c-24</td>\n",
       "      <td>c-4</td>\n",
       "      <td>91</td>\n",
       "      <td>53</td>\n",
       "      <td>0.368056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dep_delayed_15min Month DayofMonth DayOfWeek   N   Y     ratio\n",
       "611                 c-8       c-10       c-4  65  75  0.535714\n",
       "213                c-12       c-22       c-5  75  77  0.506579\n",
       "22                  c-1        c-2       c-1  66  60  0.476190\n",
       "101                c-10       c-27       c-5  76  66  0.464789\n",
       "215                c-12       c-23       c-6  71  56  0.440945\n",
       "198                c-12       c-16       c-5  75  59  0.440299\n",
       "522                 c-6       c-26       c-1  69  53  0.434426\n",
       "197                c-12       c-15       c-5  95  67  0.413580\n",
       "265                 c-2       c-18       c-6  74  51  0.408000\n",
       "573                 c-7       c-21       c-5  86  57  0.398601\n",
       "196                c-12       c-15       c-4  78  51  0.395349\n",
       "525                 c-6       c-27       c-2  82  53  0.392593\n",
       "519                 c-6       c-24       c-6  77  49  0.388889\n",
       "45                  c-1        c-3       c-2  88  56  0.388889\n",
       "546                 c-7        c-1       c-5  98  62  0.387500\n",
       "244                c-12        c-9       c-5  86  54  0.385714\n",
       "44                  c-1        c-3       c-1  84  52  0.382353\n",
       "164                c-11       c-28       c-1  97  57  0.370130\n",
       "52                  c-1        c-5       c-3  80  47  0.370079\n",
       "641                 c-8       c-24       c-4  91  53  0.368056"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_data.sort_values(by=['ratio'], ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "months = train['Month'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "count_per_month = pd.DataFrame(train[['Month', 'dep_delayed_15min']].value_counts().reset_index(name='num_of_flights'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>dep_delayed_15min</th>\n",
       "      <th>num_of_flights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c-5</td>\n",
       "      <td>N</td>\n",
       "      <td>7230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c-4</td>\n",
       "      <td>N</td>\n",
       "      <td>7102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c-8</td>\n",
       "      <td>N</td>\n",
       "      <td>7047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c-3</td>\n",
       "      <td>N</td>\n",
       "      <td>6919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c-10</td>\n",
       "      <td>N</td>\n",
       "      <td>6904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>c-9</td>\n",
       "      <td>N</td>\n",
       "      <td>6884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>c-11</td>\n",
       "      <td>N</td>\n",
       "      <td>6781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>c-7</td>\n",
       "      <td>N</td>\n",
       "      <td>6633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>c-6</td>\n",
       "      <td>N</td>\n",
       "      <td>6547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>c-1</td>\n",
       "      <td>N</td>\n",
       "      <td>6536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>c-12</td>\n",
       "      <td>N</td>\n",
       "      <td>6271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>c-2</td>\n",
       "      <td>N</td>\n",
       "      <td>6102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>c-7</td>\n",
       "      <td>Y</td>\n",
       "      <td>2073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>c-12</td>\n",
       "      <td>Y</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>c-6</td>\n",
       "      <td>Y</td>\n",
       "      <td>1867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>c-8</td>\n",
       "      <td>Y</td>\n",
       "      <td>1783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>c-3</td>\n",
       "      <td>Y</td>\n",
       "      <td>1676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>c-1</td>\n",
       "      <td>Y</td>\n",
       "      <td>1539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>c-10</td>\n",
       "      <td>Y</td>\n",
       "      <td>1501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>c-11</td>\n",
       "      <td>Y</td>\n",
       "      <td>1397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>c-2</td>\n",
       "      <td>Y</td>\n",
       "      <td>1316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>c-5</td>\n",
       "      <td>Y</td>\n",
       "      <td>1313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>c-4</td>\n",
       "      <td>Y</td>\n",
       "      <td>1306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>c-9</td>\n",
       "      <td>Y</td>\n",
       "      <td>1279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Month dep_delayed_15min  num_of_flights\n",
       "0    c-5                 N            7230\n",
       "1    c-4                 N            7102\n",
       "2    c-8                 N            7047\n",
       "3    c-3                 N            6919\n",
       "4   c-10                 N            6904\n",
       "5    c-9                 N            6884\n",
       "6   c-11                 N            6781\n",
       "7    c-7                 N            6633\n",
       "8    c-6                 N            6547\n",
       "9    c-1                 N            6536\n",
       "10  c-12                 N            6271\n",
       "11   c-2                 N            6102\n",
       "12   c-7                 Y            2073\n",
       "13  c-12                 Y            1994\n",
       "14   c-6                 Y            1867\n",
       "15   c-8                 Y            1783\n",
       "16   c-3                 Y            1676\n",
       "17   c-1                 Y            1539\n",
       "18  c-10                 Y            1501\n",
       "19  c-11                 Y            1397\n",
       "20   c-2                 Y            1316\n",
       "21   c-5                 Y            1313\n",
       "22   c-4                 Y            1306\n",
       "23   c-9                 Y            1279"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_per_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_flights_per_month = pd.DataFrame(count_per_month.groupby(['Month'])['num_of_flights'].sum().reset_index(name='total_num_of_flights'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>total_num_of_flights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c-1</td>\n",
       "      <td>8075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c-10</td>\n",
       "      <td>8405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c-11</td>\n",
       "      <td>8178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c-12</td>\n",
       "      <td>8265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c-2</td>\n",
       "      <td>7418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>c-3</td>\n",
       "      <td>8595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>c-4</td>\n",
       "      <td>8408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>c-5</td>\n",
       "      <td>8543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>c-6</td>\n",
       "      <td>8414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>c-7</td>\n",
       "      <td>8706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>c-8</td>\n",
       "      <td>8830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>c-9</td>\n",
       "      <td>8163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Month  total_num_of_flights\n",
       "0    c-1                  8075\n",
       "1   c-10                  8405\n",
       "2   c-11                  8178\n",
       "3   c-12                  8265\n",
       "4    c-2                  7418\n",
       "5    c-3                  8595\n",
       "6    c-4                  8408\n",
       "7    c-5                  8543\n",
       "8    c-6                  8414\n",
       "9    c-7                  8706\n",
       "10   c-8                  8830\n",
       "11   c-9                  8163"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_flights_per_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_stat = pd.merge(total_flights_per_month, count_per_month[count_per_month.dep_delayed_15min == 'Y'], on='Month')\n",
    "month_stat.drop(columns=['dep_delayed_15min'], inplace=True)\n",
    "month_stat['ratio'] = month_stat.apply(lambda x: float(x['num_of_flights']) / x['total_num_of_flights'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>total_num_of_flights</th>\n",
       "      <th>num_of_flights</th>\n",
       "      <th>ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c-1</td>\n",
       "      <td>8075</td>\n",
       "      <td>1539</td>\n",
       "      <td>0.190588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c-10</td>\n",
       "      <td>8405</td>\n",
       "      <td>1501</td>\n",
       "      <td>0.178584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c-11</td>\n",
       "      <td>8178</td>\n",
       "      <td>1397</td>\n",
       "      <td>0.170824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c-12</td>\n",
       "      <td>8265</td>\n",
       "      <td>1994</td>\n",
       "      <td>0.241258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c-2</td>\n",
       "      <td>7418</td>\n",
       "      <td>1316</td>\n",
       "      <td>0.177406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>c-3</td>\n",
       "      <td>8595</td>\n",
       "      <td>1676</td>\n",
       "      <td>0.194997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>c-4</td>\n",
       "      <td>8408</td>\n",
       "      <td>1306</td>\n",
       "      <td>0.155328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>c-5</td>\n",
       "      <td>8543</td>\n",
       "      <td>1313</td>\n",
       "      <td>0.153693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>c-6</td>\n",
       "      <td>8414</td>\n",
       "      <td>1867</td>\n",
       "      <td>0.221892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>c-7</td>\n",
       "      <td>8706</td>\n",
       "      <td>2073</td>\n",
       "      <td>0.238112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>c-8</td>\n",
       "      <td>8830</td>\n",
       "      <td>1783</td>\n",
       "      <td>0.201925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>c-9</td>\n",
       "      <td>8163</td>\n",
       "      <td>1279</td>\n",
       "      <td>0.156683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Month  total_num_of_flights  num_of_flights     ratio\n",
       "0    c-1                  8075            1539  0.190588\n",
       "1   c-10                  8405            1501  0.178584\n",
       "2   c-11                  8178            1397  0.170824\n",
       "3   c-12                  8265            1994  0.241258\n",
       "4    c-2                  7418            1316  0.177406\n",
       "5    c-3                  8595            1676  0.194997\n",
       "6    c-4                  8408            1306  0.155328\n",
       "7    c-5                  8543            1313  0.153693\n",
       "8    c-6                  8414            1867  0.221892\n",
       "9    c-7                  8706            2073  0.238112\n",
       "10   c-8                  8830            1783  0.201925\n",
       "11   c-9                  8163            1279  0.156683"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "month_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(month_stat['total_num_of_flights'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19044"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(month_stat['num_of_flights'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19044"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(month_stat['num_of_flights'].values) / sum(month_stat['total_num_of_flights'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>DayofMonth</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>DepTime</th>\n",
       "      <th>UniqueCarrier</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Dest</th>\n",
       "      <th>Distance</th>\n",
       "      <th>dep_delayed_15min</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>night</th>\n",
       "      <th>morning</th>\n",
       "      <th>evening</th>\n",
       "      <th>first_half_month</th>\n",
       "      <th>before_weekends</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c-8</td>\n",
       "      <td>c-21</td>\n",
       "      <td>c-7</td>\n",
       "      <td>1934</td>\n",
       "      <td>AA</td>\n",
       "      <td>ATL</td>\n",
       "      <td>DFW</td>\n",
       "      <td>732</td>\n",
       "      <td>N</td>\n",
       "      <td>19</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c-4</td>\n",
       "      <td>c-20</td>\n",
       "      <td>c-3</td>\n",
       "      <td>1548</td>\n",
       "      <td>US</td>\n",
       "      <td>PIT</td>\n",
       "      <td>MCO</td>\n",
       "      <td>834</td>\n",
       "      <td>N</td>\n",
       "      <td>15</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c-9</td>\n",
       "      <td>c-2</td>\n",
       "      <td>c-5</td>\n",
       "      <td>1422</td>\n",
       "      <td>XE</td>\n",
       "      <td>RDU</td>\n",
       "      <td>CLE</td>\n",
       "      <td>416</td>\n",
       "      <td>N</td>\n",
       "      <td>14</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c-11</td>\n",
       "      <td>c-25</td>\n",
       "      <td>c-6</td>\n",
       "      <td>1015</td>\n",
       "      <td>OO</td>\n",
       "      <td>DEN</td>\n",
       "      <td>MEM</td>\n",
       "      <td>872</td>\n",
       "      <td>N</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c-10</td>\n",
       "      <td>c-7</td>\n",
       "      <td>c-6</td>\n",
       "      <td>1828</td>\n",
       "      <td>WN</td>\n",
       "      <td>MDW</td>\n",
       "      <td>OMA</td>\n",
       "      <td>423</td>\n",
       "      <td>Y</td>\n",
       "      <td>18</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>c-5</td>\n",
       "      <td>c-4</td>\n",
       "      <td>c-3</td>\n",
       "      <td>1618</td>\n",
       "      <td>OO</td>\n",
       "      <td>SFO</td>\n",
       "      <td>RDD</td>\n",
       "      <td>199</td>\n",
       "      <td>N</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>c-1</td>\n",
       "      <td>c-18</td>\n",
       "      <td>c-3</td>\n",
       "      <td>804</td>\n",
       "      <td>CO</td>\n",
       "      <td>EWR</td>\n",
       "      <td>DAB</td>\n",
       "      <td>884</td>\n",
       "      <td>N</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>c-1</td>\n",
       "      <td>c-24</td>\n",
       "      <td>c-2</td>\n",
       "      <td>1901</td>\n",
       "      <td>NW</td>\n",
       "      <td>DTW</td>\n",
       "      <td>IAH</td>\n",
       "      <td>1076</td>\n",
       "      <td>N</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>c-4</td>\n",
       "      <td>c-27</td>\n",
       "      <td>c-4</td>\n",
       "      <td>1515</td>\n",
       "      <td>MQ</td>\n",
       "      <td>DFW</td>\n",
       "      <td>GGG</td>\n",
       "      <td>140</td>\n",
       "      <td>N</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>c-11</td>\n",
       "      <td>c-17</td>\n",
       "      <td>c-4</td>\n",
       "      <td>1800</td>\n",
       "      <td>WN</td>\n",
       "      <td>SEA</td>\n",
       "      <td>SMF</td>\n",
       "      <td>605</td>\n",
       "      <td>N</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows  16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Month DayofMonth DayOfWeek  DepTime UniqueCarrier Origin Dest  Distance  \\\n",
       "0       c-8       c-21       c-7     1934            AA    ATL  DFW       732   \n",
       "1       c-4       c-20       c-3     1548            US    PIT  MCO       834   \n",
       "2       c-9        c-2       c-5     1422            XE    RDU  CLE       416   \n",
       "3      c-11       c-25       c-6     1015            OO    DEN  MEM       872   \n",
       "4      c-10        c-7       c-6     1828            WN    MDW  OMA       423   \n",
       "...     ...        ...       ...      ...           ...    ...  ...       ...   \n",
       "99995   c-5        c-4       c-3     1618            OO    SFO  RDD       199   \n",
       "99996   c-1       c-18       c-3      804            CO    EWR  DAB       884   \n",
       "99997   c-1       c-24       c-2     1901            NW    DTW  IAH      1076   \n",
       "99998   c-4       c-27       c-4     1515            MQ    DFW  GGG       140   \n",
       "99999  c-11       c-17       c-4     1800            WN    SEA  SMF       605   \n",
       "\n",
       "      dep_delayed_15min  hour  minute  night  morning  evening  \\\n",
       "0                     N    19      34      0        0        0   \n",
       "1                     N    15      48      0        0        0   \n",
       "2                     N    14      22      0        0        0   \n",
       "3                     N    10      15      0        1        0   \n",
       "4                     Y    18      28      0        0        0   \n",
       "...                 ...   ...     ...    ...      ...      ...   \n",
       "99995                 N    16      18      0        0        0   \n",
       "99996                 N     8       4      0        1        0   \n",
       "99997                 N    19       1      0        0        0   \n",
       "99998                 N    15      15      0        0        0   \n",
       "99999                 N    18       0      0        0        0   \n",
       "\n",
       "       first_half_month  before_weekends  \n",
       "0                     0                0  \n",
       "1                     0                0  \n",
       "2                     1                1  \n",
       "3                     0                0  \n",
       "4                     1                0  \n",
       "...                 ...              ...  \n",
       "99995                 1                0  \n",
       "99996                 0                0  \n",
       "99997                 0                0  \n",
       "99998                 0                1  \n",
       "99999                 0                1  \n",
       "\n",
       "[100000 rows x 16 columns]"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['flight'] = train['Origin'] + '-' + train['Dest']\n",
    "test['flight'] = test['Origin'] + '-' + test['Dest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_splitted(tr):\n",
    "    X_train = tr.drop(columns = ['dep_delayed_15min'])\n",
    "    y_train = tr[\"dep_delayed_15min\"].map({\"Y\": 1, \"N\": 0}).values\n",
    "    X_train_part, X_valid, y_train_part, y_valid = train_test_split(\n",
    "        X_train, y_train, test_size=0.3, random_state=17\n",
    "    )\n",
    "    return X_train_part, X_valid, y_train_part, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(model, tr):\n",
    "    X_train_part, X_valid, y_train_part, y_valid = get_train_splitted(tr)\n",
    "    model.fit(X_train_part, y_train_part)\n",
    "    model_valid_pred = model.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "    return roc_auc_score(y_valid, model_valid_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without any preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg = LogisticRegression()\n",
    "X_train_part, X_valid, y_train_part, y_valid = get_train_splitted(train[[\"Distance\", \"DepTime\", 'dep_delayed_15min']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 157 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6795697123357751"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lg.fit(X_train_part, y_train_part)\n",
    "lg_pred = lg.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "roc_auc_score(y_valid, lg_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.46 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.682202981765888"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "cv_score = cross_val_score(LogisticRegression(), train[[\"Distance\", 'DepTime']], \n",
    "                           train['dep_delayed_15min'], cv=5, scoring='roc_auc')\n",
    "np.mean(cv_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Logistic regressing with 2 features without any tuning - 0.679"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['hour'] = train['DepTime'].apply(lambda x: x // 100)\n",
    "train['hour'] = train['hour'].apply(lambda x: x if x < 24 else x // 24)\n",
    "train['minute'] = train['DepTime'].apply(lambda x: x % 100)\n",
    "\n",
    "\n",
    "test['hour'] = test['DepTime'].apply(lambda x: x // 100)\n",
    "test['hour'] = test['hour'].apply(lambda x: x if x < 24 else x // 24)\n",
    "test['minute'] = test['DepTime'].apply(lambda x: x % 100)\n",
    "\n",
    "train['night'] = train['hour'].apply(lambda x: int(x >= 24 or x < 4))\n",
    "train['morning'] = train['hour'].apply(lambda x: int(x >= 4 and x <= 10))\n",
    "train['evening'] = train['hour'].apply(lambda x: int(x >= 20 and x < 24))\n",
    "\n",
    "test['night'] = test['hour'].apply(lambda x: int(x >= 24 or x < 4))\n",
    "test['morning'] = test['hour'].apply(lambda x: int(x >= 4 and x <= 10))\n",
    "test['evening'] = test['hour'].apply(lambda x: int(x >= 20 and x < 24))\n",
    "\n",
    "# Half of the month\n",
    "train['first_half_month'] = train['DayofMonth'].apply(lambda x: int(int(x.split('-')[1]) < 15))\n",
    "\n",
    "test['first_half_month'] = test['DayofMonth'].apply(lambda x: int(int(x.split('-')[1]) < 15))\n",
    "\n",
    "#Before weekends\n",
    "train['before_weekends'] = train['DayOfWeek'].apply(lambda x: int(x in ['c-4', 'c-5']))\n",
    "\n",
    "test['before_weekends'] = test['DayOfWeek'].apply(lambda x: int(x in ['c-4', 'c-5']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['s_hour'] = np.sin(2*np.pi*train['hour']/24)\n",
    "train['c_hour'] = np.cos(2*np.pi*train['hour']/24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['carr_origin'] = train['UniqueCarrier'] + '_' + train['Origin']\n",
    "train['carr_dest'] = train['UniqueCarrier'] + '_' + train['Dest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg = LogisticRegression()\n",
    "X_train_part, X_valid, y_train_part, y_valid = get_train_splitted(train[[\"Distance\",\n",
    "                                                                         \"DepTime\",\n",
    "                                                                         'hour', \n",
    "                                                                         'minute',\n",
    "                                                                         's_hour', 'c_hour',\n",
    "                                                                        # 'night',\n",
    "                                                                        # 'morning',\n",
    "                                                                        # 'evening',\n",
    "                                                                        # 'first_half_month', \n",
    "                                                                        # 'before_weekends',\n",
    "                                                                         'dep_delayed_15min']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 533 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.679400683059044"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lg.fit(X_train_part, y_train_part)\n",
    "lg_pred = lg.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "roc_auc_score(y_valid, lg_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use distance, hour, night - 0.6884925895547058"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "distance, hour, night, evening, first half - 0.6901646352554289"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.13 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6936334296993584"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "cv_score = cross_val_score(LogisticRegression(), train[[\"Distance\", 'hour',  'night', 'before_weekends']], \n",
    "                           train['dep_delayed_15min'], cv=5, scoring='roc_auc')\n",
    "np.mean(cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ohe_repr(train_data, val_data, column_name):\n",
    "    label_binarizer = LabelBinarizer()\n",
    "    train_tr = pd.DataFrame(label_binarizer.fit_transform(train_data[column_name]),\n",
    "                            columns=[f\"{column_name}_{x}\" for x in label_binarizer.classes_])\n",
    "    val_tr = pd.DataFrame(label_binarizer.transform(val_data[column_name]),\n",
    "                          columns=[f\"{column_name}_{x}\" for x in label_binarizer.classes_])\n",
    "    return train_tr, val_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_score_with_ohe(train_dataset, ohe_columns,\n",
    "                             non_cat_features = [\"Distance\", 'hour',  'night', 'before_weekends'],\n",
    "                             model=LogisticRegression()):\n",
    "\n",
    "    kf = KFold(n_splits=5)\n",
    "    X = train_dataset[[*non_cat_features, *ohe_columns]]\n",
    "    y = train_dataset['dep_delayed_15min'].map({\"Y\": 1, \"N\": 0})\n",
    "    scores = []\n",
    "    train_ohe_datasets = []\n",
    "    test_ohe_datasets = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        for ohe in ohe_columns:\n",
    "            train_ohe, test_ohe = get_ohe_repr(X_train, X_test, ohe)\n",
    "            train_ohe = train_ohe.set_index(X_train.index)\n",
    "            test_ohe = test_ohe.set_index(X_test.index)\n",
    "            train_ohe_datasets.append(train_ohe)\n",
    "            test_ohe_datasets.append(test_ohe)\n",
    "            \n",
    "        \n",
    "    \n",
    "        X_train = pd.concat([X_train, *train_ohe_datasets],axis=1)\n",
    "        X_train = X_train.drop(columns=ohe_columns)\n",
    "       \n",
    "    \n",
    "        X_test = pd.concat([X_test, *test_ohe_datasets],axis=1)\n",
    "        X_test = X_test.drop(columns=ohe_columns)\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "    \n",
    "       \n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict_proba(X_test)[:, 1]\n",
    "        score = roc_auc_score(y_test, y_pred)\n",
    "        scores.append(score)\n",
    "        train_ohe_datasets = []\n",
    "        test_ohe_datasets = []\n",
    "    return scores  \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 43.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7070355345561451"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cv_score_month = cross_val_score_with_ohe(train, [ 'Month', 'Origin', 'Dest'])\n",
    "np.mean(cv_score_month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 4.29 GiB for an array with shape (80000, 14410) and data type int32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22616\\1864999987.py\u001b[0m in \u001b[0;36mcross_val_score_with_ohe\u001b[1;34m(train_dataset, ohe_columns, non_cat_features, model)\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mohe\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mohe_columns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m             \u001b[0mtrain_ohe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_ohe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_ohe_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mohe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m             \u001b[0mtrain_ohe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_ohe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0mtest_ohe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_ohe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22616\\3890699459.py\u001b[0m in \u001b[0;36mget_ohe_repr\u001b[1;34m(train_data, val_data, column_name)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_ohe_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mlabel_binarizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLabelBinarizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     train_tr = pd.DataFrame(label_binarizer.fit_transform(train_data[column_name]),\n\u001b[0m\u001b[0;32m      4\u001b[0m                             columns=[f\"{column_name}_{x}\" for x in label_binarizer.classes_])\n\u001b[0;32m      5\u001b[0m     val_tr = pd.DataFrame(label_binarizer.transform(val_data[column_name]),\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\wpm_matching_py373\\lib\\site-packages\\sklearn\\preprocessing\\_label.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    453\u001b[0m             \u001b[0mShape\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mbinary\u001b[0m \u001b[0mproblems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m         \"\"\"\n\u001b[1;32m--> 455\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    456\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\wpm_matching_py373\\lib\\site-packages\\sklearn\\preprocessing\\_label.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    484\u001b[0m                               \u001b[0mpos_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    485\u001b[0m                               \u001b[0mneg_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneg_label\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 486\u001b[1;33m                               sparse_output=self.sparse_output)\n\u001b[0m\u001b[0;32m    487\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\wpm_matching_py373\\lib\\site-packages\\sklearn\\preprocessing\\_label.py\u001b[0m in \u001b[0;36mlabel_binarize\u001b[1;34m(y, classes, neg_label, pos_label, sparse_output)\u001b[0m\n\u001b[0;32m    675\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msparse_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    676\u001b[0m         \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 677\u001b[1;33m         \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    678\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mneg_label\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 4.29 GiB for an array with shape (80000, 14410) and data type int32"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cv_score_lg = cross_val_score_with_ohe(train, ['Month', 'Origin', 'Dest', 'UniqueCarrier','h-DoM', 'h-carrier',\n",
    "                                                   'DoM-carrier',  'Dest-h', 'd-hour-carrier' ])\n",
    "np.mean(cv_score_lg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:34:14] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:39:07] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:43:50] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:47:53] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:52:16] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Wall time: 22min 21s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7426032398065219"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "xgb_model = XGBClassifier(seed=17)\n",
    "\n",
    "cv_score_month = cross_val_score_with_ohe(train, \n",
    "                                          [ 'Month', 'Origin', 'Dest',  'UniqueCarrier', 'DayOfWeek',\n",
    "                                          'DayofMonth'],\n",
    "                                           non_cat_features=[\"Distance\", 'hour',  'night', 'before_weekends',\n",
    "                                                             'first_half_month', 'evening',\n",
    "                                                             'DepTime'],\n",
    "                                          model=xgb_model)\n",
    "np.mean(cv_score_month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [(a, b) for a in max_leaves for b in max_depth ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([7, 15, 31, 63], 3)\n",
      "([7, 15, 31, 63], 4)\n",
      "([7, 15, 31, 63], 5)\n",
      "([7, 15, 31, 63], 6)\n",
      "([7, 15, 31, 63], -1)\n"
     ]
    }
   ],
   "source": [
    "for v in itertools.product(max_leaves, max_depth):\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:20:52] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:22:14] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:23:25] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:24:44] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:26:00] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "lr: 0.001 score: 0.7041452453100712\n",
      "[14:27:23] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:28:42] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:30:01] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:31:14] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:32:20] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "lr: 0.0021544346900318843 score: 0.7063106927358358\n",
      "[14:33:24] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:34:29] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:35:37] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:36:52] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:38:07] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "lr: 0.004641588833612777 score: 0.709049721714101\n",
      "[14:39:22] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:40:45] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:42:09] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:43:26] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:44:40] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "lr: 0.01 score: 0.7128856809774519\n",
      "[14:45:55] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:47:08] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:48:32] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:50:17] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:51:33] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "lr: 0.021544346900318832 score: 0.7190490490797649\n",
      "[14:52:47] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:54:31] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:55:47] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:57:01] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:58:16] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "lr: 0.046415888336127774 score: 0.7308541565791082\n",
      "[14:59:29] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:00:49] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:02:04] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:03:20] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:04:39] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "lr: 0.1 score: 0.7398266663317467\n",
      "[15:05:58] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:07:20] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:08:39] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:09:58] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:11:25] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "lr: 0.21544346900318823 score: 0.7449005337570094\n",
      "[15:12:47] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:14:07] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:15:20] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:16:37] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:17:57] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "lr: 0.46415888336127775 score: 0.7411242730626366\n",
      "[15:19:11] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:20:25] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:21:38] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:22:50] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:23:54] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "lr: 1.0 score: 0.7256371664503052\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0.001, 0.7041452453100712],\n",
       " [0.0021544346900318843, 0.7063106927358358],\n",
       " [0.004641588833612777, 0.709049721714101],\n",
       " [0.01, 0.7128856809774519],\n",
       " [0.021544346900318832, 0.7190490490797649],\n",
       " [0.046415888336127774, 0.7308541565791082],\n",
       " [0.1, 0.7398266663317467],\n",
       " [0.21544346900318823, 0.7449005337570094],\n",
       " [0.46415888336127775, 0.7411242730626366],\n",
       " [1.0, 0.7256371664503052]]"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max_leaves = [7, ] \n",
    "learning_rate = np.logspace(-3, 0, 10)\n",
    "scores = []\n",
    "for lr in learning_rate:\n",
    "    xgb_model = XGBClassifier(seed=17, max_depth=6, learning_rate=lr)\n",
    "    cv_score_month = cross_val_score_with_ohe(train, \n",
    "                                          [ 'Month', 'Origin', 'Dest',  'UniqueCarrier', 'DayOfWeek',\n",
    "                                          'DayofMonth'],\n",
    "                                           non_cat_features=[\"Distance\", 'hour',  'night', 'before_weekends',\n",
    "                                                             'first_half_month', 'evening',\n",
    "                                                             'DepTime'],\n",
    "                                          model=xgb_model)\n",
    "    score = np.mean(cv_score_month)\n",
    "    print(f\"lr: {lr} score: {score}\")\n",
    "    scores.append([lr, score])\n",
    "scores    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:42:40] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:43:50] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:45:05] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:46:14] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:47:30] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "xgb_model = XGBClassifier(seed=17, max_depth=6, learning_rate=0.215)\n",
    "cv_score_month = cross_val_score_with_ohe(train, \n",
    "                                          [ 'Month', 'Origin', 'Dest',  'UniqueCarrier', 'DayOfWeek',\n",
    "                                          'DayofMonth'],\n",
    "                                           non_cat_features=[\"Distance\", 'hour',  'night', 'before_weekends',\n",
    "                                                             'first_half_month', 'evening',\n",
    "                                                             'DepTime'],\n",
    "                                          model=xgb_model)\n",
    "score = np.mean(cv_score_month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7449877482495924"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost and Linear Regression combinations using OHE only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(X, y, train_index, test_index, ohe_columns, \n",
    "                    non_cat_features = [\"Distance\", 'hour',  'night', 'before_weekends'],\n",
    "                    model=LogisticRegression()):\n",
    "    X_train, X_test = X.iloc[train_index][[*non_cat_features, *ohe_columns]], X.iloc[test_index][[*non_cat_features, *ohe_columns]]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    train_ohe_datasets = []\n",
    "    test_ohe_datasets = []\n",
    "    for ohe in ohe_columns:\n",
    "        train_ohe, test_ohe = get_ohe_repr(X_train, X_test, ohe)\n",
    "        train_ohe = train_ohe.set_index(X_train.index)\n",
    "        test_ohe = test_ohe.set_index(X_test.index)\n",
    "        train_ohe_datasets.append(train_ohe)\n",
    "        test_ohe_datasets.append(test_ohe)\n",
    "            \n",
    "        \n",
    "    \n",
    "    X_train = pd.concat([X_train, *train_ohe_datasets],axis=1)\n",
    "    X_train = X_train.drop(columns=ohe_columns)\n",
    "       \n",
    "    \n",
    "    X_test = pd.concat([X_test, *test_ohe_datasets],axis=1)\n",
    "    X_test = X_test.drop(columns=ohe_columns)\n",
    "        \n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "       \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict_proba(X_test)[:, 1]\n",
    "    return y_pred\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def cross_val_score_with_ohe_comb(train_dataset, lg_ohe_columns, xgb_ohe_columns, log_regr, xgboost, coef = 0.4,\n",
    "                                  non_cat_features_lg = [\"Distance\", 'hour',  'night', 'before_weekends'],\n",
    "                                  non_cat_features_xgb = [\"Distance\", 'hour',  'night', 'before_weekends']):\n",
    "\n",
    "    kf = KFold(n_splits=5)\n",
    "    X = train_dataset.drop(columns=['dep_delayed_15min'])\n",
    "    y = train_dataset['dep_delayed_15min'].map({\"Y\": 1, \"N\": 0})\n",
    "    scores = []\n",
    "    scores_lg = []\n",
    "    scores_xgb = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        y_test = y.iloc[test_index]\n",
    "        y_pred_lg = get_predictions(X, y, train_index, test_index, lg_ohe_columns, non_cat_features_lg, log_regr)\n",
    "        \n",
    "        scores_lg.append(roc_auc_score(y_test, y_pred_lg))\n",
    "        \n",
    "        y_pred_xgb = get_predictions(X, y, train_index, test_index, xgb_ohe_columns, non_cat_features_xgb, xgboost)\n",
    "        \n",
    "        scores_xgb.append(roc_auc_score(y_test, y_pred_xgb))\n",
    "        \n",
    "        y_pred_final = coef * y_pred_lg + (1 - coef) * y_pred_xgb\n",
    "        \n",
    "        score = roc_auc_score(y_test, y_pred_final)\n",
    "        scores.append(score)\n",
    "    return scores, scores_lg, scores_xgb  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:55:55] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:57:23] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:58:45] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:00:12] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:01:40] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.7070355345561451\n",
      "0.7449877482495924\n",
      "0.7343971120582669\n",
      "Wall time: 7min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "log_regr = LogisticRegression()\n",
    "xgb_model = XGBClassifier(seed=17, max_depth=6, learning_rate=0.215)\n",
    "\n",
    "cv_score_combination, cv_lg, cv_xgb = cross_val_score_with_ohe_comb(train, \n",
    "                                                                    coef=0.5,\n",
    "                                                                    lg_ohe_columns=[ 'Month', 'Origin', 'Dest'],\n",
    "                              log_regr=log_regr, xgboost=xgb_model, \n",
    "                              xgb_ohe_columns=['Month', 'Origin', 'Dest',  'UniqueCarrier', 'DayOfWeek','DayofMonth'],\n",
    "                              non_cat_features_xgb=[\"Distance\", 'hour',  'night', 'before_weekends', \n",
    "                                                    'first_half_month', 'evening', 'DepTime'])\n",
    "print(np.mean(cv_lg))\n",
    "print(np.mean(cv_xgb))\n",
    "print(np.mean(cv_score_combination))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7070355345561451"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cv_lg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7449877482495924"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cv_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_full(train, test, ohe_columns, non_cat_columns, model):\n",
    "    X_train, X_test = train[[*non_cat_columns, *ohe_columns]], test[[*non_cat_columns, *ohe_columns]]\n",
    "    y_train = train['dep_delayed_15min'].map({\"Y\": 1, \"N\": 0})\n",
    "    train_ohe_datasets = []\n",
    "    test_ohe_datasets = []\n",
    "    for ohe in ohe_columns:\n",
    "        train_ohe, test_ohe = get_ohe_repr(X_train, X_test, ohe)\n",
    "        train_ohe = train_ohe.set_index(X_train.index)\n",
    "        test_ohe = test_ohe.set_index(X_test.index)\n",
    "        train_ohe_datasets.append(train_ohe)\n",
    "        test_ohe_datasets.append(test_ohe)\n",
    "            \n",
    "        \n",
    "    \n",
    "    X_train = pd.concat([X_train, *train_ohe_datasets],axis=1)\n",
    "    X_train = X_train.drop(columns=ohe_columns)\n",
    "       \n",
    "    \n",
    "    X_test = pd.concat([X_test, *test_ohe_datasets],axis=1)\n",
    "    X_test = X_test.drop(columns=ohe_columns)\n",
    "        \n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "       \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict_proba(X_test)[:, 1]\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_regr = LogisticRegression()\n",
    "xgb_model = XGBClassifier(seed=17, max_depth=6, learning_rate=0.215)\n",
    "\n",
    "lg_pred = get_prediction_full(train, test, ohe_columns = [ 'Month', 'Origin', 'Dest'], non_cat_columns = )\n",
    "\n",
    "cross_val_score_with_ohe_comb(train, \n",
    "                                                                    coef=0.05,\n",
    "                                                                    lg_ohe_columns=[ 'Month', 'Origin', 'Dest'],\n",
    "                              log_regr=log_regr, xgboost=xgb_model, \n",
    "                              xgb_ohe_columns=['Month', 'Origin', 'Dest',  'UniqueCarrier', 'DayOfWeek','DayofMonth'],\n",
    "                              non_cat_features_xgb=[\"Distance\", 'hour',  'night', 'before_weekends', \n",
    "                                                    'first_half_month', 'evening', 'DepTime'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:15:19] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "xgb_model = XGBClassifier(seed=17, max_depth=6, learning_rate=0.215)\n",
    "preds = get_prediction_full(train, test, \n",
    "                    ohe_columns = ['Month', 'Origin', 'Dest',  'UniqueCarrier', 'DayOfWeek','DayofMonth'], \n",
    "                    non_cat_columns = [\"Distance\", 'hour',  'night', 'before_weekends', \n",
    "                                                    'first_half_month', 'evening', 'DepTime'], model=xgb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "    sample_sub = pd.read_csv( 'sample_submission.csv.zip', \n",
    "                             index_col='id')\n",
    "    sample_sub['dep_delayed_15min'] = preds\n",
    "    sample_sub.to_csv('xgb_pred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature hashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders import HashingEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions_hash(X, y, train_index, test_index, ohe_columns, \n",
    "                    non_cat_features = [\"Distance\", 'hour',  'night', 'before_weekends'],\n",
    "                    model=LogisticRegression()):\n",
    "    X_train, X_test = X.iloc[train_index][[*non_cat_features, *ohe_columns]], X.iloc[test_index][[*non_cat_features, *ohe_columns]]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    hashing_enc = HashingEncoder(cols=ohe_columns, n_components=1000).fit(X_train, y_train)\n",
    "                    \n",
    "    X_train_hashing = hashing_enc.transform(X_train.reset_index(drop=True))\n",
    "    X_test_hashing = hashing_enc.transform(X_test.reset_index(drop=True))\n",
    "    \n",
    "        \n",
    "    scaler = StandardScaler()\n",
    "    X_train_hashing = scaler.fit_transform(X_train_hashing)\n",
    "    X_test_hashing = scaler.transform(X_test_hashing)\n",
    "    \n",
    "       \n",
    "    model.fit(X_train_hashing, y_train)\n",
    "    y_pred = model.predict_proba(X_test_hashing)[:, 1]\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_score_with_hashing(train_dataset, ohe_columns, \n",
    "                                 non_cat_features = [\"Distance\", 'hour',  'night', 'before_weekends'], \n",
    "                                 model = LogisticRegression()):\n",
    "\n",
    "    kf = KFold(n_splits=5)\n",
    "    X = train_dataset.drop(columns=['dep_delayed_15min'])\n",
    "    y = train_dataset['dep_delayed_15min'].map({\"Y\": 1, \"N\": 0})\n",
    "    scores = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        y_test = y.iloc[test_index]\n",
    "        y_pred = get_predictions_hash(X, y, train_index, test_index, ohe_columns, non_cat_features, model)\n",
    "        \n",
    "        score = roc_auc_score(y_test, y_pred)\n",
    "        scores.append(score)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9min 46s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7144784769811987"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cv_score_lg = cross_val_score_with_hashing(train, [ 'Month', 'Origin', 'Dest', 'UniqueCarrier'])\n",
    "np.mean(cv_score_lg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10min 9s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7132788456419014"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cv_score_lg = cross_val_score_with_hashing(train, ['Month', 'Origin', 'Dest', 'UniqueCarrier','h-DoM', 'h-carrier',\n",
    "                                                   'DoM-carrier' ])\n",
    "np.mean(cv_score_lg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:28:19] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:32:09] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:35:55] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:39:59] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:43:19] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Wall time: 18min 45s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7352371955763075"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "xgb_model = XGBClassifier(seed=17, max_depth=6, learning_rate=0.215)\n",
    "\n",
    "cv_score_xgb = cross_val_score_with_hashing(train,\n",
    "                                            ['Month', 'Origin', 'Dest',  'UniqueCarrier', 'DayOfWeek','DayofMonth'],\n",
    "                                            non_cat_features= [\"Distance\", 'hour',  'night', 'before_weekends'],\n",
    "                                            model=xgb_model)\n",
    "np.mean(cv_score_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_score_with_hashing_comb(train_dataset, ohe_columns_1, ohe_columns_2, model_1, model_2, coef,\n",
    "                                      non_cat_features_1 = [\"Distance\", 'hour',  'night', 'before_weekends'], \n",
    "                                      non_cat_features_2 = [\"Distance\", 'hour',  'night', 'before_weekends']):\n",
    "\n",
    "    kf = KFold(n_splits=5)\n",
    "    X = train_dataset.drop(columns=['dep_delayed_15min'])\n",
    "    y = train_dataset['dep_delayed_15min'].map({\"Y\": 1, \"N\": 0})\n",
    "    scores = []\n",
    "    scores_1 = []\n",
    "    scores_2 = []\n",
    "    print(coef)\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        y_test = y.iloc[test_index]\n",
    "        y_pred_1 = get_predictions_hash(X, y, train_index, test_index, ohe_columns_1, non_cat_features_1, model_1)\n",
    "        \n",
    "        scores_1.append(roc_auc_score(y_test, y_pred_1))\n",
    "        \n",
    "        y_pred_2 = get_predictions_hash(X, y, train_index, test_index, ohe_columns_2, non_cat_features_2, model_2)\n",
    "        \n",
    "        scores_2.append(roc_auc_score(y_test, y_pred_2))\n",
    "        \n",
    "        y_pred = coef * y_pred_1 + (1 - coef) * y_pred_2\n",
    "        \n",
    "        score = roc_auc_score(y_test, y_pred)\n",
    "        scores.append(score)\n",
    "    return scores, scores_1, scores_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2\n",
      "[11:25:46] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:36:36] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:47:35] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:59:05] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:11:17] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.7144784769811987\n",
      "0.7423956527728055\n",
      "0.7446741406283047\n",
      "Wall time: 56min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lg = LogisticRegression()\n",
    "xgb_model = XGBClassifier(seed=17, max_depth=6, learning_rate=0.215, n_estimators=500)\n",
    "\n",
    "scores, scores_lg, scores_xgb = cross_val_score_with_hashing_comb(\n",
    "    train, \n",
    "    ohe_columns_1 = ['Month', 'Origin', 'Dest', 'UniqueCarrier'], \n",
    "    ohe_columns_2 = ['Month', 'Origin', 'Dest',  'UniqueCarrier', 'DayOfWeek','DayofMonth'],\n",
    "    model_1 = lg, model_2 = xgb_model, coef = 0.25,\n",
    "    non_cat_features_2 = [\"Distance\", 'hour',  'night', 'before_weekends', \n",
    "                          'first_half_month', 'evening', 'DepTime']\n",
    "    \n",
    ")\n",
    "\n",
    "print(np.mean(scores_lg))\n",
    "print(np.mean(scores_xgb))\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 0.35 \n",
    " 0.7144784769811987\n",
    "0.7423956527728055\n",
    "0.7441798181792334\n",
    "\n",
    "0.25\n",
    "0.7144784769811987\n",
    "0.7423956527728055\n",
    "0.7447270604248639"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['summer'] = (train['Month'].isin(['c-6', 'c-7', 'c-8'])).astype(np.int32)\n",
    "train['autumn'] = (train['Month'].isin(['c-9', 'c-10', 'c-11'])).astype(np.int32)\n",
    "train['winter'] = (train['Month'].isin(['c-12', 'c-1', 'c-2'])).astype(np.int32)\n",
    "train['spring'] = (train['Month'].isin(['c-3', 'c-4', 'c-5'])).astype(np.int32)\n",
    "\n",
    "\n",
    "train['daytime'] = pd.cut(train['hour'], bins=[0, 6, 12, 18, 23], labels = [0,1,2,3], include_lowest=True).astype('object')\n",
    "train['DistanceBin'] = pd.cut(train['Distance'], bins=[0,100,300,800,1500,3000], labels = [0,1,2,3,4], include_lowest = True)\n",
    "train['DistanceBin'].fillna(0, inplace = True)\n",
    "train['DistanceBin'] = train['DistanceBin'].astype('object')\n",
    "\n",
    "\n",
    "train['h-DoM'] = train['hour'].astype('str') + '----' + train['DayofMonth']\n",
    "train['h-carrier'] = train['hour'].astype('str') + '----' + train['UniqueCarrier']\n",
    "train['DoM-carrier'] = train['DayofMonth'] + '----' +  train['UniqueCarrier']\n",
    "\n",
    "train['Dest-DoM'] = train['Dest'] + '--' + train['DayofMonth']\n",
    "train['Dest-h'] = train['Dest'] + '--' + train['hour'].astype('str')\n",
    "train['Dest-carrier'] = train['Dest'] + '--' + train['UniqueCarrier']\n",
    "\n",
    "train['d-hour-carrier'] = train['Dest'] + train['hour'].astype('str') + train['UniqueCarrier']\n",
    "train['m-hour-carrier'] = train['DayofMonth'] + train['hour'].astype('str') + train['UniqueCarrier']\n",
    "train['d-hour-dom'] = train['Dest'] + train['hour'].astype('str') + train['DayofMonth'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10min 12s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7075226533866947"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cv_score_lg = cross_val_score_with_hashing(train, ['Month', 'Origin', 'Dest', 'UniqueCarrier','h-DoM', 'h-carrier',\n",
    "                                                   'DoM-carrier', 'Dest-DoM', 'Dest-h',\n",
    "                                                   'Dest-carrier', 'd-hour-carrier', 'm-hour-carrier', 'd-hour-dom'\n",
    "                                                  ])\n",
    "np.mean(cv_score_lg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders import TargetEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions_target(X, y, train_index, test_index, ohe_columns, \n",
    "                    non_cat_features = [\"Distance\", 'hour',  'night', 'before_weekends'],\n",
    "                    model=LogisticRegression()):\n",
    "    X_train, X_test = X.iloc[train_index][[*non_cat_features, *ohe_columns]], X.iloc[test_index][[*non_cat_features, *ohe_columns]]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    targ_enc  = TargetEncoder(cols=ohe_columns, smoothing=8, min_samples_leaf=5).fit(X_train, y_train)\n",
    "                    \n",
    "    X_train_hashing = targ_enc.transform(X_train.reset_index(drop=True))\n",
    "    X_test_hashing = targ_enc.transform(X_test.reset_index(drop=True))\n",
    "    \n",
    "        \n",
    "    scaler = StandardScaler()\n",
    "    X_train_hashing = scaler.fit_transform(X_train_hashing)\n",
    "    X_test_hashing = scaler.transform(X_test_hashing)\n",
    "    \n",
    "       \n",
    "    model.fit(X_train_hashing, y_train)\n",
    "    y_pred = model.predict_proba(X_test_hashing)[:, 1]\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_score_with_target(train_dataset, ohe_columns, \n",
    "                                 non_cat_features = [\"Distance\", 'hour',  'night', 'before_weekends'], \n",
    "                                 model = LogisticRegression()):\n",
    "\n",
    "    kf = KFold(n_splits=5)\n",
    "    X = train_dataset.drop(columns=['dep_delayed_15min'])\n",
    "    y = train_dataset['dep_delayed_15min'].map({\"Y\": 1, \"N\": 0})\n",
    "    scores = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        y_test = y.iloc[test_index]\n",
    "        y_pred = get_predictions_target(X, y, train_index, test_index, ohe_columns, non_cat_features, model)\n",
    "        \n",
    "        score = roc_auc_score(y_test, y_pred)\n",
    "        scores.append(score)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.66 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7112463111584454"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cv_score_lg = cross_val_score_with_target(train, \n",
    "                                          non_cat_features=[\"Distance\", 'hour',  'night', 'before_weekends', \n",
    "                          'first_half_month', 'evening', 'DepTime'],\n",
    "                                          ohe_columns = ['Month', 'Origin', 'Dest', 'UniqueCarrier', 'DayOfWeek','DayofMonth'])\n",
    "np.mean(cv_score_lg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:29:50] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:30:10] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:30:34] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:30:54] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:31:13] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Wall time: 1min 43s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7392948138500158"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "xgb_model = XGBClassifier(seed=17, max_depth=6, learning_rate=0.215, n_estimators=500)\n",
    "\n",
    "cv_score_xgb = cross_val_score_with_target(train,\n",
    "                                            ohe_columns = ['Month', 'Origin', 'Dest', 'UniqueCarrier', 'DayOfWeek','DayofMonth'],\n",
    "                                             non_cat_features=[\"Distance\", 'hour',  'night', 'before_weekends', \n",
    "                          'first_half_month', 'evening', 'DepTime'],\n",
    "                                            model=xgb_model)\n",
    "np.mean(cv_score_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weight of evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders import WOEEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions_woe(X, y, train_index, test_index, ohe_columns, \n",
    "                    non_cat_features = [\"Distance\", 'hour',  'night', 'before_weekends'],\n",
    "                    model=LogisticRegression()):\n",
    "    X_train, X_test = X.iloc[train_index][[*non_cat_features, *ohe_columns]], X.iloc[test_index][[*non_cat_features, *ohe_columns]]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    woe_enc = WOEEncoder(cols=ohe_columns, random_state=17).fit(X_train, y_train)\n",
    "                    \n",
    "    X_train_hashing = woe_enc.transform(X_train.reset_index(drop=True))\n",
    "    X_test_hashing = woe_enc.transform(X_test.reset_index(drop=True))\n",
    "    \n",
    "        \n",
    "    scaler = StandardScaler()\n",
    "    X_train_hashing = scaler.fit_transform(X_train_hashing)\n",
    "    X_test_hashing = scaler.transform(X_test_hashing)\n",
    "    \n",
    "       \n",
    "    model.fit(X_train_hashing, y_train)\n",
    "    y_pred = model.predict_proba(X_test_hashing)[:, 1]\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_score_with_any_enc(train_dataset, ohe_columns, \n",
    "                                pred_func,\n",
    "                                 non_cat_features = [\"Distance\", 'hour',  'night', 'before_weekends'],\n",
    "                                 model = LogisticRegression()):\n",
    "\n",
    "    kf = KFold(n_splits=5)\n",
    "    X = train_dataset.drop(columns=['dep_delayed_15min'])\n",
    "    y = train_dataset['dep_delayed_15min'].map({\"Y\": 1, \"N\": 0})\n",
    "    scores = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        y_test = y.iloc[test_index]\n",
    "        y_pred = pred_func(X, y, train_index, test_index, ohe_columns, non_cat_features, model)\n",
    "        \n",
    "        score = roc_auc_score(y_test, y_pred)\n",
    "        scores.append(score)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6.03 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7111922787028627"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cv_score_lg = cross_val_score_with_any_enc(train, \n",
    "                                          pred_func=get_predictions_woe,\n",
    "                                          non_cat_features=[\"Distance\", 'hour',  'night', 'before_weekends', \n",
    "                          'first_half_month', 'evening', 'DepTime'],\n",
    "                                          ohe_columns = ['Month', 'Origin', 'Dest', 'UniqueCarrier', 'DayOfWeek','DayofMonth'])\n",
    "np.mean(cv_score_lg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:35:05] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:35:25] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:35:44] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:36:04] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:36:25] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Wall time: 1min 39s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7397628568457904"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "xgb_model = XGBClassifier(seed=17, max_depth=6, learning_rate=0.215, n_estimators=500)\n",
    "\n",
    "cv_score_xgb = cross_val_score_with_any_enc(train,pred_func=get_predictions_woe,\n",
    "                                            ohe_columns = ['Month', 'Origin', 'Dest', 'UniqueCarrier',\n",
    "                                                           'DayOfWeek','DayofMonth'],\n",
    "                                            non_cat_features=[\"Distance\", 'hour',  'night', 'before_weekends', \n",
    "                                                               'first_half_month', 'evening', 'DepTime'],\n",
    "                                            model=xgb_model)\n",
    "np.mean(cv_score_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders import BinaryEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions_binary_enc(X, y, train_index, test_index, ohe_columns, \n",
    "                    non_cat_features = [\"Distance\", 'hour',  'night', 'before_weekends'],\n",
    "                    model=LogisticRegression()):\n",
    "    X_train, X_test = X.iloc[train_index][[*non_cat_features, *ohe_columns]], X.iloc[test_index][[*non_cat_features, *ohe_columns]]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    binary_enc = BinaryEncoder(cols=ohe_columns).fit(X_train, y_train)\n",
    "                    \n",
    "    X_train_hashing = binary_enc.transform(X_train.reset_index(drop=True))\n",
    "    X_test_hashing = binary_enc.transform(X_test.reset_index(drop=True))\n",
    "    \n",
    "        \n",
    "    scaler = StandardScaler()\n",
    "    X_train_hashing = scaler.fit_transform(X_train_hashing)\n",
    "    X_test_hashing = scaler.transform(X_test_hashing)\n",
    "    \n",
    "       \n",
    "    model.fit(X_train_hashing, y_train)\n",
    "    y_pred = model.predict_proba(X_test_hashing)[:, 1]\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7025043885012281"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cv_score_lg = cross_val_score_with_any_enc(train, \n",
    "                                          pred_func=get_predictions_binary_enc,\n",
    "                                          non_cat_features=[\"Distance\", 'hour',  'night', 'before_weekends', \n",
    "                          'first_half_month', 'evening', 'DepTime'],\n",
    "                                          ohe_columns = ['Month', 'Origin', 'Dest', 'UniqueCarrier', 'DayOfWeek','DayofMonth'])\n",
    "np.mean(cv_score_lg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:38:16] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:38:48] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:39:20] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:39:53] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:40:25] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Wall time: 2min 47s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7344605558010876"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "xgb_model = XGBClassifier(seed=17, max_depth=6, learning_rate=0.215, n_estimators=500)\n",
    "\n",
    "cv_score_xgb = cross_val_score_with_any_enc(train,pred_func=get_predictions_binary_enc,\n",
    "                                            ohe_columns = ['Month', 'Origin', 'Dest', 'UniqueCarrier',\n",
    "                                                           'DayOfWeek','DayofMonth'],\n",
    "                                            non_cat_features=[\"Distance\", 'hour',  'night', 'before_weekends', \n",
    "                                                               'first_half_month', 'evening', 'DepTime'],\n",
    "                                            model=xgb_model)\n",
    "np.mean(cv_score_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns = ['dep_delayed_15min'])\n",
    "y_train = train[\"dep_delayed_15min\"].map({\"Y\": 1, \"N\": 0}).values\n",
    "X_train_part, X_valid, y_train_part, y_valid = train_test_split( X_train, y_train, test_size=0.3, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "hashing_enc = HashingEncoder(cols=['Month', 'Origin', 'Dest'], n_components=1000).fit(X_train_part, y_train_part)\n",
    "X_train_hashing = hashing_enc.transform(X_train_part.reset_index(drop=True))\n",
    "X_valid_hashing = hashing_enc.transform(X_valid.reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_hashing = X_train_hashing.drop(columns=[ 'DayofMonth', 'DayOfWeek', 'DepTime', 'UniqueCarrier'])\n",
    "X_valid_hashing = X_valid_hashing.drop(columns=[ 'DayofMonth', 'DayOfWeek', 'DepTime', 'UniqueCarrier'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_hashing = scaler.fit_transform(X_train_hashing)\n",
    "X_valid_hashing = scaler.transform(X_valid_hashing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg = LogisticRegression()\n",
    "lg.fit(X_train_hashing, y_train_part)\n",
    "y_pred = lg.predict_proba(X_valid_hashing)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7076558612671646"
      ]
     },
     "execution_count": 549,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6853003067835673"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb_month = LabelBinarizer()\n",
    "month = pd.DataFrame(lb_month.fit_transform(train['Month']), columns=[f\"m_{x}\" for x in lb_month.classes_])\n",
    "\n",
    "train_mod = pd.concat([train,month],axis=1)\n",
    "train_mod = train_mod.drop(columns=['Month'])\n",
    "\n",
    "get_score(lg, train_mod.drop(columns=['DayofMonth', 'DayOfWeek', 'UniqueCarrier', 'Origin', 'Dest']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6892126359938712"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb_dest = LabelBinarizer()\n",
    "dest = pd.DataFrame(lb_unique.fit_transform(train['Dest']), columns=lb_unique.classes_)\n",
    "\n",
    "lb_origin = LabelBinarizer()\n",
    "origin = pd.DataFrame(lb_unique.fit_transform(train['Origin']), columns=lb_unique.classes_)\n",
    "\n",
    "train_mod = pd.concat([train, \n",
    "                       month,\n",
    "                       dest, \n",
    "                       origin\n",
    "                      ],axis=1)\n",
    "train_mod = train_mod.drop(columns=['Month', 'DayofMonth', 'DayOfWeek', 'UniqueCarrier', 'Origin', 'Dest'])\n",
    "\n",
    "get_score(LogisticRegression(), train_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 3s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6894253479718501"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train_mod = train\n",
    "train_mod['flight'] = train_mod['Origin'] + '-' + train_mod['Dest']\n",
    "\n",
    "lb_flight = LabelBinarizer()\n",
    "flight = pd.DataFrame(lb_flight.fit_transform(train_mod['flight']), columns=lb_flight.classes_)\n",
    "\n",
    "\n",
    "train_mod = pd.concat([train,\n",
    "                        month,\n",
    "                       flight,\n",
    "                        dest, \n",
    "                       origin\n",
    "                      ],axis=1)\n",
    "train_mod = train_mod.drop(columns=['Month', 'DayofMonth', 'DayOfWeek', 'UniqueCarrier', 'Origin', 'Dest', 'flight'])\n",
    "\n",
    "get_score(LogisticRegression(), train_mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flight is a very doubtful feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.52 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6880076042138357"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "lb_day_of_week = LabelBinarizer()\n",
    "day_of_week = pd.DataFrame(lb_day_of_week.fit_transform(train['DayOfWeek']), \n",
    "                           columns=[f\"dw_{x}\" for x in lb_day_of_week.classes_])\n",
    "\n",
    "train_mod = pd.concat([train, \n",
    "                       day_of_week, dest, \n",
    "                       origin,\n",
    "                       month\n",
    "                      ],axis=1)\n",
    "train_mod = train_mod.drop(columns=['Month', 'DayofMonth', 'DayOfWeek', 'UniqueCarrier', 'Origin', 'Dest', 'flight'])\n",
    "\n",
    "get_score(LogisticRegression(), train_mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Day of Week is also a doubtful feature with OHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.690344799196128"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb_day_of_month = LabelBinarizer()\n",
    "day_of_month = pd.DataFrame(lb_day_of_month.fit_transform(train['DayofMonth']),\n",
    "                            columns=[f\"dm_{x}\" for x in lb_day_of_month.classes_])\n",
    "\n",
    "train_mod = pd.concat([train, \n",
    "                       day_of_month, dest, \n",
    "                       origin,\n",
    "                       month\n",
    "                      ],axis=1)\n",
    "train_mod = train_mod.drop(columns=['Month', 'DayofMonth', 'DayOfWeek', 'UniqueCarrier', 'Origin', 'Dest', 'flight'])\n",
    "\n",
    "get_score(LogisticRegression(), train_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 14.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_mod = pd.concat([train, \n",
    "                       day_of_month,\n",
    "                       day_of_week,\n",
    "                       flight,\n",
    "                      unique_carrier,\n",
    "                       dest, \n",
    "                       origin,\n",
    "                       month\n",
    "                      ],axis=1)\n",
    "train_mod = train_mod.drop(columns=['Month', 'DayofMonth', 'DayOfWeek', 'UniqueCarrier', 'Origin', 'Dest', 'flight'])\n",
    "\n",
    "#get_score(LogisticRegression(), train_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DepTime</th>\n",
       "      <th>Distance</th>\n",
       "      <th>dep_delayed_15min</th>\n",
       "      <th>dm_c-1</th>\n",
       "      <th>dm_c-10</th>\n",
       "      <th>dm_c-11</th>\n",
       "      <th>dm_c-12</th>\n",
       "      <th>dm_c-13</th>\n",
       "      <th>dm_c-14</th>\n",
       "      <th>dm_c-15</th>\n",
       "      <th>...</th>\n",
       "      <th>m_c-11</th>\n",
       "      <th>m_c-12</th>\n",
       "      <th>m_c-2</th>\n",
       "      <th>m_c-3</th>\n",
       "      <th>m_c-4</th>\n",
       "      <th>m_c-5</th>\n",
       "      <th>m_c-6</th>\n",
       "      <th>m_c-7</th>\n",
       "      <th>m_c-8</th>\n",
       "      <th>m_c-9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1934</td>\n",
       "      <td>732</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1548</td>\n",
       "      <td>834</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1422</td>\n",
       "      <td>416</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1015</td>\n",
       "      <td>872</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1828</td>\n",
       "      <td>423</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  624 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   DepTime  Distance dep_delayed_15min  dm_c-1  dm_c-10  dm_c-11  dm_c-12  \\\n",
       "0     1934       732                 N       0        0        0        0   \n",
       "1     1548       834                 N       0        0        0        0   \n",
       "2     1422       416                 N       0        0        0        0   \n",
       "3     1015       872                 N       0        0        0        0   \n",
       "4     1828       423                 Y       0        0        0        0   \n",
       "\n",
       "   dm_c-13  dm_c-14  dm_c-15  ...  m_c-11  m_c-12  m_c-2  m_c-3  m_c-4  m_c-5  \\\n",
       "0        0        0        0  ...       0       0      0      0      0      0   \n",
       "1        0        0        0  ...       0       0      0      0      1      0   \n",
       "2        0        0        0  ...       0       0      0      0      0      0   \n",
       "3        0        0        0  ...       1       0      0      0      0      0   \n",
       "4        0        0        0  ...       0       0      0      0      0      0   \n",
       "\n",
       "   m_c-6  m_c-7  m_c-8  m_c-9  \n",
       "0      0      0      1      0  \n",
       "1      0      0      0      0  \n",
       "2      0      0      0      1  \n",
       "3      0      0      0      0  \n",
       "4      0      0      0      0  \n",
       "\n",
       "[5 rows x 624 columns]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mod.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cv_score = cross_val_score(LogisticRegression(), train_mod.drop(columns=['dep_delayed_15min']),\n",
    "                train_mod['dep_delayed_15min'], cv=5, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6984504420966946"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.69210854, 0.70278836, 0.70553505])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:   21.2s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   26.9s\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  30 | elapsed:   42.0s remaining:   24.2s\n",
      "[Parallel(n_jobs=-1)]: Done  23 out of  30 | elapsed:   42.1s remaining:   12.8s\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  30 | elapsed:   45.9s remaining:    5.0s\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 646. MiB for an array with shape (5079, 33334) and data type int32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\Viktoryia_Khlystun\\Miniconda3\\envs\\wpm_matching_py373\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 436, in _process_worker\n    r = call_item()\n  File \"C:\\Users\\Viktoryia_Khlystun\\Miniconda3\\envs\\wpm_matching_py373\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 288, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"C:\\Users\\Viktoryia_Khlystun\\Miniconda3\\envs\\wpm_matching_py373\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 595, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\Viktoryia_Khlystun\\Miniconda3\\envs\\wpm_matching_py373\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n    for func, args, kwargs in self.items]\n  File \"C:\\Users\\Viktoryia_Khlystun\\Miniconda3\\envs\\wpm_matching_py373\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"C:\\Users\\Viktoryia_Khlystun\\Miniconda3\\envs\\wpm_matching_py373\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 509, in _fit_and_score\n    X_test, y_test = _safe_split(estimator, X, y, test, train)\n  File \"C:\\Users\\Viktoryia_Khlystun\\Miniconda3\\envs\\wpm_matching_py373\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 201, in _safe_split\n    X_subset = _safe_indexing(X, indices)\n  File \"C:\\Users\\Viktoryia_Khlystun\\Miniconda3\\envs\\wpm_matching_py373\\lib\\site-packages\\sklearn\\utils\\__init__.py\", line 411, in _safe_indexing\n    return _pandas_indexing(X, indices, indices_dtype, axis=axis)\n  File \"C:\\Users\\Viktoryia_Khlystun\\Miniconda3\\envs\\wpm_matching_py373\\lib\\site-packages\\sklearn\\utils\\__init__.py\", line 213, in _pandas_indexing\n    return indexer[:, key] if axis else indexer[key]\n  File \"C:\\Users\\Viktoryia_Khlystun\\Miniconda3\\envs\\wpm_matching_py373\\lib\\site-packages\\pandas\\core\\indexing.py\", line 895, in __getitem__\n    return self._getitem_axis(maybe_callable, axis=axis)\n  File \"C:\\Users\\Viktoryia_Khlystun\\Miniconda3\\envs\\wpm_matching_py373\\lib\\site-packages\\pandas\\core\\indexing.py\", line 1492, in _getitem_axis\n    return self._get_list_axis(key, axis=axis)\n  File \"C:\\Users\\Viktoryia_Khlystun\\Miniconda3\\envs\\wpm_matching_py373\\lib\\site-packages\\pandas\\core\\indexing.py\", line 1474, in _get_list_axis\n    return self.obj._take_with_is_copy(key, axis=axis)\n  File \"C:\\Users\\Viktoryia_Khlystun\\Miniconda3\\envs\\wpm_matching_py373\\lib\\site-packages\\pandas\\core\\generic.py\", line 3600, in _take_with_is_copy\n  File \"C:\\Users\\Viktoryia_Khlystun\\Miniconda3\\envs\\wpm_matching_py373\\lib\\site-packages\\pandas\\core\\generic.py\", line 3587, in take\n    indices, axis=self._get_block_manager_axis(axis), verify=True\n  File \"C:\\Users\\Viktoryia_Khlystun\\Miniconda3\\envs\\wpm_matching_py373\\lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 1475, in take\n    new_axis=new_labels, indexer=indexer, axis=axis, allow_dups=True\n  File \"C:\\Users\\Viktoryia_Khlystun\\Miniconda3\\envs\\wpm_matching_py373\\lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 1319, in reindex_indexer\n    for blk in self.blocks\n  File \"C:\\Users\\Viktoryia_Khlystun\\Miniconda3\\envs\\wpm_matching_py373\\lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 1319, in <listcomp>\n    for blk in self.blocks\n  File \"C:\\Users\\Viktoryia_Khlystun\\Miniconda3\\envs\\wpm_matching_py373\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\", line 1396, in take_nd\n    values, indexer, axis=axis, allow_fill=allow_fill, fill_value=fill_value\n  File \"C:\\Users\\Viktoryia_Khlystun\\Miniconda3\\envs\\wpm_matching_py373\\lib\\site-packages\\pandas\\core\\algorithms.py\", line 1754, in take_nd\n    out = np.empty(out_shape, dtype=dtype)\nMemoryError: Unable to allocate 646. MiB for an array with shape (5079, 33334) and data type int32\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15064\\1148260801.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mlog_regr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mgrid_search\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_regr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'roc_auc'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_part\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_part\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\wpm_matching_py373\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    708\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 710\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    711\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    712\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\wpm_matching_py373\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1149\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1150\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1151\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\wpm_matching_py373\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    687\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 689\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    690\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    691\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\wpm_matching_py373\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1054\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1055\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1056\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1057\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\wpm_matching_py373\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    933\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 935\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    936\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\wpm_matching_py373\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\wpm_matching_py373\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    423\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 425\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\wpm_matching_py373\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 646. MiB for an array with shape (5079, 33334) and data type int32"
     ]
    }
   ],
   "source": [
    "X_train_part = train_mod.drop(columns=['dep_delayed_15min'])\n",
    "y_train_part = train_mod['dep_delayed_15min']\n",
    "params = {'C': np.logspace(-3, 1, 10)}\n",
    "log_regr = LogisticRegression()\n",
    "grid_search = GridSearchCV(log_regr, params, cv=3, verbose=10, n_jobs=-1, scoring='roc_auc')\n",
    "grid_search.fit(X_train_part, y_train_part)\n",
    "\n",
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6964405336551912"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>dep_delayed_15min</th>\n",
       "      <th>num_of_flights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>c-7</td>\n",
       "      <td>Y</td>\n",
       "      <td>2073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>c-12</td>\n",
       "      <td>Y</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>c-6</td>\n",
       "      <td>Y</td>\n",
       "      <td>1867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>c-8</td>\n",
       "      <td>Y</td>\n",
       "      <td>1783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>c-3</td>\n",
       "      <td>Y</td>\n",
       "      <td>1676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>c-1</td>\n",
       "      <td>Y</td>\n",
       "      <td>1539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>c-10</td>\n",
       "      <td>Y</td>\n",
       "      <td>1501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>c-11</td>\n",
       "      <td>Y</td>\n",
       "      <td>1397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>c-2</td>\n",
       "      <td>Y</td>\n",
       "      <td>1316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>c-5</td>\n",
       "      <td>Y</td>\n",
       "      <td>1313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>c-4</td>\n",
       "      <td>Y</td>\n",
       "      <td>1306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>c-9</td>\n",
       "      <td>Y</td>\n",
       "      <td>1279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Month dep_delayed_15min  num_of_flights\n",
       "12   c-7                 Y            2073\n",
       "13  c-12                 Y            1994\n",
       "14   c-6                 Y            1867\n",
       "15   c-8                 Y            1783\n",
       "16   c-3                 Y            1676\n",
       "17   c-1                 Y            1539\n",
       "18  c-10                 Y            1501\n",
       "19  c-11                 Y            1397\n",
       "20   c-2                 Y            1316\n",
       "21   c-5                 Y            1313\n",
       "22   c-4                 Y            1306\n",
       "23   c-9                 Y            1279"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_per_month[count_per_month.dep_delayed_15min == 'Y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>DayofMonth</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>DepTime</th>\n",
       "      <th>UniqueCarrier</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Dest</th>\n",
       "      <th>Distance</th>\n",
       "      <th>dep_delayed_15min</th>\n",
       "      <th>flight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c-8</td>\n",
       "      <td>c-21</td>\n",
       "      <td>c-7</td>\n",
       "      <td>1934</td>\n",
       "      <td>AA</td>\n",
       "      <td>ATL</td>\n",
       "      <td>DFW</td>\n",
       "      <td>732</td>\n",
       "      <td>N</td>\n",
       "      <td>ATL-DFW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c-4</td>\n",
       "      <td>c-20</td>\n",
       "      <td>c-3</td>\n",
       "      <td>1548</td>\n",
       "      <td>US</td>\n",
       "      <td>PIT</td>\n",
       "      <td>MCO</td>\n",
       "      <td>834</td>\n",
       "      <td>N</td>\n",
       "      <td>PIT-MCO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c-9</td>\n",
       "      <td>c-2</td>\n",
       "      <td>c-5</td>\n",
       "      <td>1422</td>\n",
       "      <td>XE</td>\n",
       "      <td>RDU</td>\n",
       "      <td>CLE</td>\n",
       "      <td>416</td>\n",
       "      <td>N</td>\n",
       "      <td>RDU-CLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c-11</td>\n",
       "      <td>c-25</td>\n",
       "      <td>c-6</td>\n",
       "      <td>1015</td>\n",
       "      <td>OO</td>\n",
       "      <td>DEN</td>\n",
       "      <td>MEM</td>\n",
       "      <td>872</td>\n",
       "      <td>N</td>\n",
       "      <td>DEN-MEM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c-10</td>\n",
       "      <td>c-7</td>\n",
       "      <td>c-6</td>\n",
       "      <td>1828</td>\n",
       "      <td>WN</td>\n",
       "      <td>MDW</td>\n",
       "      <td>OMA</td>\n",
       "      <td>423</td>\n",
       "      <td>Y</td>\n",
       "      <td>MDW-OMA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Month DayofMonth DayOfWeek  DepTime UniqueCarrier Origin Dest  Distance  \\\n",
       "0   c-8       c-21       c-7     1934            AA    ATL  DFW       732   \n",
       "1   c-4       c-20       c-3     1548            US    PIT  MCO       834   \n",
       "2   c-9        c-2       c-5     1422            XE    RDU  CLE       416   \n",
       "3  c-11       c-25       c-6     1015            OO    DEN  MEM       872   \n",
       "4  c-10        c-7       c-6     1828            WN    MDW  OMA       423   \n",
       "\n",
       "  dep_delayed_15min   flight  \n",
       "0                 N  ATL-DFW  \n",
       "1                 N  PIT-MCO  \n",
       "2                 N  RDU-CLE  \n",
       "3                 N  DEN-MEM  \n",
       "4                 Y  MDW-OMA  "
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_splitted(train):\n",
    "    X_train = train[[\"Distance\", \"DepTime\"]].values\n",
    "    y_train = train[\"dep_delayed_15min\"].map({\"Y\": 1, \"N\": 0}).values\n",
    "    X_train_part, X_valid, y_train_part, y_valid = train_test_split(\n",
    "        X_train, y_train, test_size=0.3, random_state=17\n",
    "    )\n",
    "    return X_train_part, X_valid, y_train_part, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test[[\"Distance\", \"DepTime\"]].values\n",
    "\n",
    "X_train_part, X_valid, y_train_part, y_valid = get_train_splitted(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:26:12] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Wall time: 2.14 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7001228548770644"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "xgb_model = XGBClassifier(seed=17)\n",
    "\n",
    "xgb_model.fit(X_train_part, y_train_part)\n",
    "xgb_valid_pred = xgb_model.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "roc_auc_score(y_valid, xgb_valid_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:19:43] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "xgb_model.fit(X_train, y_train)\n",
    "xgb_test_pred = xgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "pd.Series(xgb_test_pred, name=\"dep_delayed_15min\").to_csv(\n",
    "    \"xgb_2feat.csv\", index_label=\"id\", header=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Flight'] = train.apply(lambda x: f\"{x['Origin']}-{x['Dest']}\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>DayofMonth</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>DepTime</th>\n",
       "      <th>UniqueCarrier</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Dest</th>\n",
       "      <th>Distance</th>\n",
       "      <th>dep_delayed_15min</th>\n",
       "      <th>flight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c-8</td>\n",
       "      <td>c-21</td>\n",
       "      <td>c-7</td>\n",
       "      <td>1934</td>\n",
       "      <td>AA</td>\n",
       "      <td>ATL</td>\n",
       "      <td>DFW</td>\n",
       "      <td>732</td>\n",
       "      <td>N</td>\n",
       "      <td>ATL-DFW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c-4</td>\n",
       "      <td>c-20</td>\n",
       "      <td>c-3</td>\n",
       "      <td>1548</td>\n",
       "      <td>US</td>\n",
       "      <td>PIT</td>\n",
       "      <td>MCO</td>\n",
       "      <td>834</td>\n",
       "      <td>N</td>\n",
       "      <td>PIT-MCO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c-9</td>\n",
       "      <td>c-2</td>\n",
       "      <td>c-5</td>\n",
       "      <td>1422</td>\n",
       "      <td>XE</td>\n",
       "      <td>RDU</td>\n",
       "      <td>CLE</td>\n",
       "      <td>416</td>\n",
       "      <td>N</td>\n",
       "      <td>RDU-CLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c-11</td>\n",
       "      <td>c-25</td>\n",
       "      <td>c-6</td>\n",
       "      <td>1015</td>\n",
       "      <td>OO</td>\n",
       "      <td>DEN</td>\n",
       "      <td>MEM</td>\n",
       "      <td>872</td>\n",
       "      <td>N</td>\n",
       "      <td>DEN-MEM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c-10</td>\n",
       "      <td>c-7</td>\n",
       "      <td>c-6</td>\n",
       "      <td>1828</td>\n",
       "      <td>WN</td>\n",
       "      <td>MDW</td>\n",
       "      <td>OMA</td>\n",
       "      <td>423</td>\n",
       "      <td>Y</td>\n",
       "      <td>MDW-OMA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Month DayofMonth DayOfWeek  DepTime UniqueCarrier Origin Dest  Distance  \\\n",
       "0   c-8       c-21       c-7     1934            AA    ATL  DFW       732   \n",
       "1   c-4       c-20       c-3     1548            US    PIT  MCO       834   \n",
       "2   c-9        c-2       c-5     1422            XE    RDU  CLE       416   \n",
       "3  c-11       c-25       c-6     1015            OO    DEN  MEM       872   \n",
       "4  c-10        c-7       c-6     1828            WN    MDW  OMA       423   \n",
       "\n",
       "  dep_delayed_15min   flight  \n",
       "0                 N  ATL-DFW  \n",
       "1                 N  PIT-MCO  \n",
       "2                 N  RDU-CLE  \n",
       "3                 N  DEN-MEM  \n",
       "4                 Y  MDW-OMA  "
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DepTime</th>\n",
       "      <th>Distance</th>\n",
       "      <th>dep_delayed_15min</th>\n",
       "      <th>ABE</th>\n",
       "      <th>ABI</th>\n",
       "      <th>ABQ</th>\n",
       "      <th>ABY</th>\n",
       "      <th>ACK</th>\n",
       "      <th>ACT</th>\n",
       "      <th>ACV</th>\n",
       "      <th>...</th>\n",
       "      <th>TYS</th>\n",
       "      <th>VCT</th>\n",
       "      <th>VIS</th>\n",
       "      <th>VLD</th>\n",
       "      <th>VPS</th>\n",
       "      <th>WRG</th>\n",
       "      <th>WYS</th>\n",
       "      <th>XNA</th>\n",
       "      <th>YAK</th>\n",
       "      <th>YUM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1934</td>\n",
       "      <td>732</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1548</td>\n",
       "      <td>834</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1422</td>\n",
       "      <td>416</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1015</td>\n",
       "      <td>872</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1828</td>\n",
       "      <td>423</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  581 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   DepTime  Distance dep_delayed_15min  ABE  ABI  ABQ  ABY  ACK  ACT  ACV  \\\n",
       "0     1934       732                 N    0    0    0    0    0    0    0   \n",
       "1     1548       834                 N    0    0    0    0    0    0    0   \n",
       "2     1422       416                 N    0    0    0    0    0    0    0   \n",
       "3     1015       872                 N    0    0    0    0    0    0    0   \n",
       "4     1828       423                 Y    0    0    0    0    0    0    0   \n",
       "\n",
       "   ...  TYS  VCT  VIS  VLD  VPS  WRG  WYS  XNA  YAK  YUM  \n",
       "0  ...    0    0    0    0    0    0    0    0    0    0  \n",
       "1  ...    0    0    0    0    0    0    0    0    0    0  \n",
       "2  ...    0    0    0    0    0    0    0    0    0    0  \n",
       "3  ...    0    0    0    0    0    0    0    0    0    0  \n",
       "4  ...    0    0    0    0    0    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 581 columns]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mod.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:14:35] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Wall time: 32.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7312887104118719"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# lb_dest = LabelBinarizer()\n",
    "# dest = pd.DataFrame(lb_unique.fit_transform(train['Dest']), columns=lb_unique.classes_)\n",
    "\n",
    "# lb_origin = LabelBinarizer()\n",
    "# origin = pd.DataFrame(lb_unique.fit_transform(train['Origin']), columns=lb_unique.classes_)\n",
    "\n",
    "train_mod = pd.concat([train, \n",
    "                       day_of_month,\n",
    "                   #    flight,\n",
    "                       day_of_week,\n",
    "                        unique_carrier,\n",
    "                         month,\n",
    "                         origin, pd.DataFrame(dest, columns=[f\"dest_{x}\" for x in dest.columns])\n",
    "                      ],axis=1)\n",
    "train_mod = train_mod.drop(columns=['Month', 'DayofMonth', 'DayOfWeek', 'UniqueCarrier', 'Origin', 'Dest', 'flight'])\n",
    "\n",
    "get_score(XGBClassifier(seed=17), train_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['summer'] = train['Month'].apply(lambda x: int(x in ['c-6', 'c-7', 'c-8']))\n",
    "train['is_holiday'] = train['DayOfWeek'].apply(lambda x: int(x in ['c-6', 'c-7']))\n",
    "train['uniq_carr_origin'] = train.apply(lambda x: x['UniqueCarrier'] + '-' + x['Origin'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>DayofMonth</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>DepTime</th>\n",
       "      <th>UniqueCarrier</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Dest</th>\n",
       "      <th>Distance</th>\n",
       "      <th>dep_delayed_15min</th>\n",
       "      <th>flight</th>\n",
       "      <th>summer</th>\n",
       "      <th>is_holiday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c-8</td>\n",
       "      <td>c-21</td>\n",
       "      <td>c-7</td>\n",
       "      <td>1934</td>\n",
       "      <td>AA</td>\n",
       "      <td>ATL</td>\n",
       "      <td>DFW</td>\n",
       "      <td>732</td>\n",
       "      <td>N</td>\n",
       "      <td>ATL-DFW</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c-4</td>\n",
       "      <td>c-20</td>\n",
       "      <td>c-3</td>\n",
       "      <td>1548</td>\n",
       "      <td>US</td>\n",
       "      <td>PIT</td>\n",
       "      <td>MCO</td>\n",
       "      <td>834</td>\n",
       "      <td>N</td>\n",
       "      <td>PIT-MCO</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c-9</td>\n",
       "      <td>c-2</td>\n",
       "      <td>c-5</td>\n",
       "      <td>1422</td>\n",
       "      <td>XE</td>\n",
       "      <td>RDU</td>\n",
       "      <td>CLE</td>\n",
       "      <td>416</td>\n",
       "      <td>N</td>\n",
       "      <td>RDU-CLE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c-11</td>\n",
       "      <td>c-25</td>\n",
       "      <td>c-6</td>\n",
       "      <td>1015</td>\n",
       "      <td>OO</td>\n",
       "      <td>DEN</td>\n",
       "      <td>MEM</td>\n",
       "      <td>872</td>\n",
       "      <td>N</td>\n",
       "      <td>DEN-MEM</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c-10</td>\n",
       "      <td>c-7</td>\n",
       "      <td>c-6</td>\n",
       "      <td>1828</td>\n",
       "      <td>WN</td>\n",
       "      <td>MDW</td>\n",
       "      <td>OMA</td>\n",
       "      <td>423</td>\n",
       "      <td>Y</td>\n",
       "      <td>MDW-OMA</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>c-5</td>\n",
       "      <td>c-4</td>\n",
       "      <td>c-3</td>\n",
       "      <td>1618</td>\n",
       "      <td>OO</td>\n",
       "      <td>SFO</td>\n",
       "      <td>RDD</td>\n",
       "      <td>199</td>\n",
       "      <td>N</td>\n",
       "      <td>SFO-RDD</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>c-1</td>\n",
       "      <td>c-18</td>\n",
       "      <td>c-3</td>\n",
       "      <td>804</td>\n",
       "      <td>CO</td>\n",
       "      <td>EWR</td>\n",
       "      <td>DAB</td>\n",
       "      <td>884</td>\n",
       "      <td>N</td>\n",
       "      <td>EWR-DAB</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>c-1</td>\n",
       "      <td>c-24</td>\n",
       "      <td>c-2</td>\n",
       "      <td>1901</td>\n",
       "      <td>NW</td>\n",
       "      <td>DTW</td>\n",
       "      <td>IAH</td>\n",
       "      <td>1076</td>\n",
       "      <td>N</td>\n",
       "      <td>DTW-IAH</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>c-4</td>\n",
       "      <td>c-27</td>\n",
       "      <td>c-4</td>\n",
       "      <td>1515</td>\n",
       "      <td>MQ</td>\n",
       "      <td>DFW</td>\n",
       "      <td>GGG</td>\n",
       "      <td>140</td>\n",
       "      <td>N</td>\n",
       "      <td>DFW-GGG</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>c-11</td>\n",
       "      <td>c-17</td>\n",
       "      <td>c-4</td>\n",
       "      <td>1800</td>\n",
       "      <td>WN</td>\n",
       "      <td>SEA</td>\n",
       "      <td>SMF</td>\n",
       "      <td>605</td>\n",
       "      <td>N</td>\n",
       "      <td>SEA-SMF</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Month DayofMonth DayOfWeek  DepTime UniqueCarrier Origin Dest  Distance  \\\n",
       "0       c-8       c-21       c-7     1934            AA    ATL  DFW       732   \n",
       "1       c-4       c-20       c-3     1548            US    PIT  MCO       834   \n",
       "2       c-9        c-2       c-5     1422            XE    RDU  CLE       416   \n",
       "3      c-11       c-25       c-6     1015            OO    DEN  MEM       872   \n",
       "4      c-10        c-7       c-6     1828            WN    MDW  OMA       423   \n",
       "...     ...        ...       ...      ...           ...    ...  ...       ...   \n",
       "99995   c-5        c-4       c-3     1618            OO    SFO  RDD       199   \n",
       "99996   c-1       c-18       c-3      804            CO    EWR  DAB       884   \n",
       "99997   c-1       c-24       c-2     1901            NW    DTW  IAH      1076   \n",
       "99998   c-4       c-27       c-4     1515            MQ    DFW  GGG       140   \n",
       "99999  c-11       c-17       c-4     1800            WN    SEA  SMF       605   \n",
       "\n",
       "      dep_delayed_15min   flight  summer  is_holiday  \n",
       "0                     N  ATL-DFW       1           1  \n",
       "1                     N  PIT-MCO       0           0  \n",
       "2                     N  RDU-CLE       0           0  \n",
       "3                     N  DEN-MEM       0           1  \n",
       "4                     Y  MDW-OMA       0           1  \n",
       "...                 ...      ...     ...         ...  \n",
       "99995                 N  SFO-RDD       0           0  \n",
       "99996                 N  EWR-DAB       0           0  \n",
       "99997                 N  DTW-IAH       0           0  \n",
       "99998                 N  DFW-GGG       0           0  \n",
       "99999                 N  SEA-SMF       0           0  \n",
       "\n",
       "[100000 rows x 12 columns]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lb_month = LabelBinarizer()\n",
    "# month = pd.DataFrame(lb_month.fit_transform(train['Month']), columns=[f\"m_{x}\" for x in lb_month.classes_])\n",
    "\n",
    "# lb_day_of_month = LabelBinarizer()\n",
    "# day_of_month = pd.DataFrame(lb_day_of_month.fit_transform(train['DayofMonth']),\n",
    "#                             columns=[f\"dm_{x}\" for x in lb_day_of_month.classes_])\n",
    "\n",
    "# lb_day_of_week = LabelBinarizer()\n",
    "# day_of_week = pd.DataFrame(lb_day_of_week.fit_transform(train['DayOfWeek']), \n",
    "#                            columns=[f\"dw_{x}\" for x in lb_day_of_week.classes_])\n",
    "\n",
    "# lb_unique = LabelBinarizer()\n",
    "# unique_carrier = pd.DataFrame(lb_unique.fit_transform(train['UniqueCarrier']), columns=lb_unique.classes_)\n",
    "\n",
    "# lb_flight = LabelBinarizer()\n",
    "# flight = pd.DataFrame(lb_flight.fit_transform(train['Flight']), columns=lb_flight.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_modified = pd.concat([train,month, day_of_month, day_of_week, unique_carrier, flight],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_modified = train_modified.drop(columns=['Month', 'DayofMonth', 'DayOfWeek', 'UniqueCarrier',\n",
    "                                              'Origin', 'Dest', 'Flight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train\n",
    "del month\n",
    "del day_of_month\n",
    "del day_of_week\n",
    "del unique_carrier\n",
    "del flight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DepTime</th>\n",
       "      <th>Distance</th>\n",
       "      <th>dep_delayed_15min</th>\n",
       "      <th>m_c-1</th>\n",
       "      <th>m_c-10</th>\n",
       "      <th>m_c-11</th>\n",
       "      <th>m_c-12</th>\n",
       "      <th>m_c-2</th>\n",
       "      <th>m_c-3</th>\n",
       "      <th>m_c-4</th>\n",
       "      <th>...</th>\n",
       "      <th>XNA-IAH</th>\n",
       "      <th>XNA-LAX</th>\n",
       "      <th>XNA-LGA</th>\n",
       "      <th>XNA-ORD</th>\n",
       "      <th>XNA-SLC</th>\n",
       "      <th>YAK-CDV</th>\n",
       "      <th>YAK-JNU</th>\n",
       "      <th>YUM-IPL</th>\n",
       "      <th>YUM-LAX</th>\n",
       "      <th>YUM-PHX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1934</td>\n",
       "      <td>732</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1548</td>\n",
       "      <td>834</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1422</td>\n",
       "      <td>416</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1015</td>\n",
       "      <td>872</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1828</td>\n",
       "      <td>423</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>1618</td>\n",
       "      <td>199</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>804</td>\n",
       "      <td>884</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>1901</td>\n",
       "      <td>1076</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>1515</td>\n",
       "      <td>140</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>1800</td>\n",
       "      <td>605</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows  4504 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       DepTime  Distance dep_delayed_15min  m_c-1  m_c-10  m_c-11  m_c-12  \\\n",
       "0         1934       732                 N      0       0       0       0   \n",
       "1         1548       834                 N      0       0       0       0   \n",
       "2         1422       416                 N      0       0       0       0   \n",
       "3         1015       872                 N      0       0       1       0   \n",
       "4         1828       423                 Y      0       1       0       0   \n",
       "...        ...       ...               ...    ...     ...     ...     ...   \n",
       "99995     1618       199                 N      0       0       0       0   \n",
       "99996      804       884                 N      1       0       0       0   \n",
       "99997     1901      1076                 N      1       0       0       0   \n",
       "99998     1515       140                 N      0       0       0       0   \n",
       "99999     1800       605                 N      0       0       1       0   \n",
       "\n",
       "       m_c-2  m_c-3  m_c-4  ...  XNA-IAH  XNA-LAX  XNA-LGA  XNA-ORD  XNA-SLC  \\\n",
       "0          0      0      0  ...        0        0        0        0        0   \n",
       "1          0      0      1  ...        0        0        0        0        0   \n",
       "2          0      0      0  ...        0        0        0        0        0   \n",
       "3          0      0      0  ...        0        0        0        0        0   \n",
       "4          0      0      0  ...        0        0        0        0        0   \n",
       "...      ...    ...    ...  ...      ...      ...      ...      ...      ...   \n",
       "99995      0      0      0  ...        0        0        0        0        0   \n",
       "99996      0      0      0  ...        0        0        0        0        0   \n",
       "99997      0      0      0  ...        0        0        0        0        0   \n",
       "99998      0      0      1  ...        0        0        0        0        0   \n",
       "99999      0      0      0  ...        0        0        0        0        0   \n",
       "\n",
       "       YAK-CDV  YAK-JNU  YUM-IPL  YUM-LAX  YUM-PHX  \n",
       "0            0        0        0        0        0  \n",
       "1            0        0        0        0        0  \n",
       "2            0        0        0        0        0  \n",
       "3            0        0        0        0        0  \n",
       "4            0        0        0        0        0  \n",
       "...        ...      ...      ...      ...      ...  \n",
       "99995        0        0        0        0        0  \n",
       "99996        0        0        0        0        0  \n",
       "99997        0        0        0        0        0  \n",
       "99998        0        0        0        0        0  \n",
       "99999        0        0        0        0        0  \n",
       "\n",
       "[100000 rows x 4504 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_modified.drop(columns = ['dep_delayed_15min'])\n",
    "y_train = train_modified[\"dep_delayed_15min\"].map({\"Y\": 1, \"N\": 0}).values\n",
    "X_train_part, X_valid, y_train_part, y_valid = train_test_split(\n",
    "        X_train, y_train, test_size=0.3, random_state=17\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6835109807916165"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg = LogisticRegression(random_state=17)\n",
    "lg.fit(X_train_part, y_train_part)\n",
    "lg_valid_pred = lg.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "roc_auc_score(y_valid, lg_valid_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:25:26] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Wall time: 7min 30s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7230444782675478"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "xgb_model = XGBClassifier(seed=17)\n",
    "\n",
    "xgb_model.fit(X_train_part, y_train_part)\n",
    "xgb_valid_pred = xgb_model.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "roc_auc_score(y_valid, xgb_valid_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed: 16.0min\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed: 65.8min\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed: 120.1min\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed: 193.0min\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed: 226.7min\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed: 337.5min\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed: 419.0min\n",
      "[Parallel(n_jobs=-1)]: Done  69 tasks      | elapsed: 546.8min\n",
      "[Parallel(n_jobs=-1)]: Done  82 tasks      | elapsed: 577.2min\n",
      "[Parallel(n_jobs=-1)]: Done  96 out of 100 | elapsed: 601.1min remaining: 25.0min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed: 605.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:17:43] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Wall time: 10h 11min 30s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=7, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
       "              n_jobs=8, num_parallel_tree=1, objective='binary:logistic',\n",
       "              predictor='auto', random_state=17, reg_alpha=0, reg_lambda=1,\n",
       "              scale_pos_weight=1, seed=17, subsample=1, tree_method='exact',\n",
       "              use_label_encoder=True, ...)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "param_dist = {\n",
    "    #\"min_child_weight\" : [1,3,6],\n",
    "              'max_leaves': [7, 15, 31, 63], \n",
    "              'max_depth': [3, 4, 5, 6, -1]}\n",
    "grid_search = GridSearchCV(xgb_model, param_grid=param_dist, cv = 5, \n",
    "                                   verbose=10, n_jobs=-1)\n",
    "grid_search.fit(X_train_part, y_train_part)\n",
    "\n",
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "space={'learning_rate': hp.choice('learning_rate',np.logspace(-3, 0, 10)) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': <hyperopt.pyll.base.Apply at 0x2b8b7f11ba8>}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(space):\n",
    "    clf=XGBClassifier(\n",
    "                    n_estimators=500, max_depth = 6,\n",
    "                    min_child_weight=1,\n",
    "                    learning_rate = float(space['learning_rate']),\n",
    "                    seed=17)\n",
    "    \n",
    "    evaluation = [( X_train_part, y_train_part), ( X_valid, y_valid)]\n",
    "    \n",
    "    clf.fit(X_train_part, y_train_part,\n",
    "            eval_set=evaluation,\n",
    "            eval_metric=\"auc\",\n",
    "            early_stopping_rounds=10,verbose=False)\n",
    "    \n",
    "\n",
    "   # pred = clf.predict(X_test)\n",
    "    xgb_valid_pred = clf.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "    roc_auc = roc_auc_score(y_valid, xgb_valid_pred)\n",
    "    print(f\"learning rate: {float(space['learning_rate'])}\")\n",
    "    print (\"SCORE:\", roc_auc)\n",
    "    return {'loss': -roc_auc, 'status': STATUS_OK }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate: 0.001                                                                                                       \n",
      "SCORE:                                                                                                                     \n",
      "0.6964600436935819                                                                                                         \n",
      "learning rate: 0.46415888336127775                                                                                         \n",
      "SCORE:                                                                                                                     \n",
      "0.7219539159108                                                                                                            \n",
      "learning rate: 0.0021544346900318843                                                                                       \n",
      "SCORE:                                                                                                                     \n",
      "0.6964497577303855                                                                                                         \n",
      "learning rate: 0.01                                                                                                        \n",
      "SCORE:                                                                                                                     \n",
      "0.7157914125626936                                                                                                         \n",
      "learning rate: 0.021544346900318832                                                                                        \n",
      "SCORE:                                                                                                                     \n",
      "0.7196711248241168                                                                                                         \n",
      "100%|| 5/5 [1:25:17<00:00, 1023.57s/it, best loss: -0.7219539159108]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "\n",
    "best_hyperparams = fmin(fn = objective,\n",
    "                        space = space,\n",
    "                        algo = tpe.suggest,\n",
    "                        max_evals = 5,\n",
    "                        trials = trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "xgb_model = XGBClassifier(seed=17, n_estimators=500, max_depth=6, min_child_weight=1, max_leaves=7)\n",
    "param_dist = {\"learning_rate\": np.logspace(-3, 0, 10)}\n",
    "grid_search = GridSearchCV(xgb_model, param_grid=param_dist, cv = 5, \n",
    "                                   verbose=10, n_jobs=-1)\n",
    "grid_search.fit(X_train_part, y_train_part)\n",
    "\n",
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7003760107110389"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_valid_pred = grid_search.best_estimator_.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "roc_auc_score(y_valid, xgb_valid_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:40:23] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              eta=0.464, gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.463999987,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=7, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=500,\n",
       "              n_jobs=8, num_parallel_tree=1, objective='binary:logistic',\n",
       "              predictor='auto', random_state=17, reg_alpha=0, reg_lambda=1,\n",
       "              scale_pos_weight=1, seed=17, subsample=1, tree_method='exact', ...)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model = XGBClassifier(seed=17, n_estimators=500, max_depth=6, min_child_weight=1, max_leaves=7, eta=0.464)\n",
    "xgb_model.fit(X_train_part, y_train_part)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_test_pred = xgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "pd.Series(xgb_test_pred, name=\"dep_delayed_15min\").to_csv(\n",
    "    \"xgb_2feat.csv\", index_label=\"id\", header=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Flight'] = test.apply(lambda x: f\"{x['Origin']}-{x['Dest']}\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_month = pd.DataFrame(lb_month.transform(test['Month']), columns=[f\"m_{x}\" for x in lb_month.classes_])\n",
    "\n",
    "test_day_of_month = pd.DataFrame(lb_day_of_month.transform(test['DayofMonth']),\n",
    "                            columns=[f\"dm_{x}\" for x in lb_day_of_month.classes_])\n",
    "\n",
    "test_day_of_week = pd.DataFrame(lb_day_of_week.transform(test['DayOfWeek']), \n",
    "                           columns=[f\"dw_{x}\" for x in lb_day_of_week.classes_])\n",
    "\n",
    "test_unique_carrier = pd.DataFrame(lb_unique.transform(test['UniqueCarrier']), columns=lb_unique.classes_)\n",
    "\n",
    "test_flight = pd.DataFrame(lb_flight.transform(test['Flight']), columns=lb_flight.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_modified = pd.concat([test,test_month, test_day_of_month, test_day_of_week,\n",
    "                           test_unique_carrier, test_flight],axis=1)\n",
    "test_modified = test_modified.drop(columns=['Month', 'DayofMonth', 'DayOfWeek', 'UniqueCarrier',\n",
    "                                              'Origin', 'Dest', 'Flight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_test_pred = xgb_model.predict_proba(test_modified)[:, 1]\n",
    "\n",
    "pd.Series(xgb_test_pred, name=\"dep_delayed_15min\").to_csv(\n",
    "    \"xgb_3feat.csv\", index_label=\"id\", header=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(params):\n",
    "    print(\"Training with params: \")\n",
    "    print(params)\n",
    "    clf = XGBClassifier(n_estimators=500, max_depth = 6, max_leaves=7,\n",
    "                    min_child_weight=1,\n",
    "                    learning_rate = params['learning_rate'],\n",
    "                    seed=17)\n",
    "    clf.fit(X_train_part, y_train_part,\n",
    "      #      eval_set=X_valid,\n",
    "            eval_metric=\"auc\",verbose=True)\n",
    "#     gbm_model = XGBClassifier().train(params, dtrain, num_round,\n",
    "#                           evals=watchlist,\n",
    "#                           verbose_eval=True)\n",
    "    predictions = clf.predict(X_valid,\n",
    "                                    ntree_limit=clf.best_iteration + 1)\n",
    "    score = roc_auc_score(y_valid, predictions)\n",
    "    # TODO: Add the importance for the selected features\n",
    "    print(\"\\tScore {0}\\n\\n\".format(score))\n",
    "    # The score function should return the loss (1-score)\n",
    "    # since the optimize function looks for the minimum\n",
    "    loss = 1 - score\n",
    "    return {'loss': loss, 'status': STATUS_OK}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(\n",
    "             #trials, \n",
    "             random_state=17):\n",
    "    \"\"\"\n",
    "    This is the optimization function that given a space (space here) of \n",
    "    hyperparameters and a scoring function (score here), finds the best hyperparameters.\n",
    "    \"\"\"\n",
    "    # To learn more about XGBoost parameters, head to this page: \n",
    "    # https://github.com/dmlc/xgboost/blob/master/doc/parameter.md\n",
    "    space = {\n",
    "        'learning_rate': hp.choice('learning_rate',np.logspace(-3, 0, 10)),\n",
    "        'eval_metric': 'auc',\n",
    "        'objective': 'binary:logistic',\n",
    "        # Increase this number if you have more cores. Otherwise, remove it and it will default \n",
    "        # to the maxium number. \n",
    "        'nthread': 4,\n",
    "        'booster': 'gbtree',\n",
    "        'seed': random_state\n",
    "    }\n",
    "    # Use the fmin function from Hyperopt to find the best hyperparameters\n",
    "    best = fmin(score, space, algo=tpe.suggest, \n",
    "                # trials=trials, \n",
    "                max_evals=250)\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with params:                                                                                                      \n",
      "{'booster': 'gbtree', 'eval_metric': 'auc', 'learning_rate': 0.021544346900318832, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 17}\n",
      "\tScore 0.5311457043318739                                                                                                  \n",
      "\n",
      "\n",
      "Training with params:                                                                                                      \n",
      "{'booster': 'gbtree', 'eval_metric': 'auc', 'learning_rate': 0.046415888336127774, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 17}\n",
      "\tScore 0.5350474247825341                                                                                                  \n",
      "\n",
      "\n",
      "Training with params:                                                                                                      \n",
      "{'booster': 'gbtree', 'eval_metric': 'auc', 'learning_rate': 0.21544346900318823, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 17}\n",
      "\tScore 0.5460933197275235                                                                                                  \n",
      "\n",
      "\n",
      "Training with params:                                                                                                      \n",
      "{'booster': 'gbtree', 'eval_metric': 'auc', 'learning_rate': 0.01, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 17}\n",
      "\tScore 0.5283283079245984                                                                                                  \n",
      "\n",
      "\n",
      "Training with params:                                                                                                      \n",
      "{'booster': 'gbtree', 'eval_metric': 'auc', 'learning_rate': 0.01, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 17}\n",
      "\tScore 0.5283283079245984                                                                                                  \n",
      "\n",
      "\n",
      "Training with params:                                                                                                      \n",
      "{'booster': 'gbtree', 'eval_metric': 'auc', 'learning_rate': 1.0, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 17}\n",
      "\tScore 0.5867322318237038                                                                                                  \n",
      "\n",
      "\n",
      "Training with params:                                                                                                      \n",
      "{'booster': 'gbtree', 'eval_metric': 'auc', 'learning_rate': 1.0, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 17}\n",
      "\tScore 0.5867322318237038                                                                                                  \n",
      "\n",
      "\n",
      "Training with params:                                                                                                      \n",
      "{'booster': 'gbtree', 'eval_metric': 'auc', 'learning_rate': 0.046415888336127774, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 17}\n",
      "\tScore 0.5350474247825341                                                                                                  \n",
      "\n",
      "\n",
      "Training with params:                                                                                                      \n",
      "{'booster': 'gbtree', 'eval_metric': 'auc', 'learning_rate': 0.21544346900318823, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 17}\n",
      "\tScore 0.5460933197275235                                                                                                  \n",
      "\n",
      "\n",
      "Training with params:                                                                                                      \n",
      "{'booster': 'gbtree', 'eval_metric': 'auc', 'learning_rate': 0.004641588833612777, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 17}\n",
      "\tScore 0.5248146504613179                                                                                                  \n",
      "\n",
      "\n",
      "Training with params:                                                                                                      \n",
      "{'booster': 'gbtree', 'eval_metric': 'auc', 'learning_rate': 0.021544346900318832, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 17}\n",
      "\tScore 0.5311457043318739                                                                                                  \n",
      "\n",
      "\n",
      "Training with params:                                                                                                      \n",
      "{'booster': 'gbtree', 'eval_metric': 'auc', 'learning_rate': 0.46415888336127775, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 17}\n",
      "\tScore 0.5592860830664067                                                                                                  \n",
      "\n",
      "\n",
      "Training with params:                                                                                                      \n",
      "{'booster': 'gbtree', 'eval_metric': 'auc', 'learning_rate': 0.01, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 17}\n",
      "\tScore 0.5283283079245984                                                                                                  \n",
      "\n",
      "\n",
      "Training with params:                                                                                                      \n",
      "{'booster': 'gbtree', 'eval_metric': 'auc', 'learning_rate': 0.46415888336127775, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 17}\n",
      "\tScore 0.5592860830664067                                                                                                  \n",
      "\n",
      "\n",
      "Training with params:                                                                                                      \n",
      "{'booster': 'gbtree', 'eval_metric': 'auc', 'learning_rate': 0.01, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 17}\n",
      "\tScore 0.5283283079245984                                                                                                  \n",
      "\n",
      "\n",
      "Training with params:                                                                                                      \n",
      "{'booster': 'gbtree', 'eval_metric': 'auc', 'learning_rate': 1.0, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 17}\n",
      "\tScore 0.5867322318237038                                                                                                  \n",
      "\n",
      "\n",
      "Training with params:                                                                                                      \n",
      "{'booster': 'gbtree', 'eval_metric': 'auc', 'learning_rate': 0.01, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 17}\n",
      "\tScore 0.5283283079245984                                                                                                  \n",
      "\n",
      "\n",
      "Training with params:                                                                                                      \n",
      "{'booster': 'gbtree', 'eval_metric': 'auc', 'learning_rate': 0.1, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 17}\n",
      "\tScore 0.539518917231908                                                                                                   \n",
      "\n",
      "\n",
      "Training with params:                                                                                                      \n",
      "{'booster': 'gbtree', 'eval_metric': 'auc', 'learning_rate': 0.1, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 17}\n",
      "\tScore 0.539518917231908                                                                                                   \n",
      "\n",
      "\n",
      "Training with params:                                                                                                      \n",
      "{'booster': 'gbtree', 'eval_metric': 'auc', 'learning_rate': 0.01, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 17}\n",
      "\tScore 0.5283283079245984                                                                                                  \n",
      "\n",
      "\n",
      "Training with params:                                                                                                      \n",
      "{'booster': 'gbtree', 'eval_metric': 'auc', 'learning_rate': 1.0, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 17}\n",
      "\tScore 0.5867322318237038                                                                                                  \n",
      "\n",
      "\n",
      "Training with params:                                                                                                      \n",
      "{'booster': 'gbtree', 'eval_metric': 'auc', 'learning_rate': 0.0021544346900318843, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 17}\n",
      "\tScore 0.5231284017169144                                                                                                  \n",
      "\n",
      "\n",
      "Training with params:                                                                                                      \n",
      "{'booster': 'gbtree', 'eval_metric': 'auc', 'learning_rate': 0.001, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 17}\n",
      "\tScore 0.5247063867090558                                                                                                  \n",
      "\n",
      "\n",
      "Training with params:                                                                                                      \n",
      "{'booster': 'gbtree', 'eval_metric': 'auc', 'learning_rate': 1.0, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 17}\n",
      "\tScore 0.5867322318237038                                                                                                  \n",
      "\n",
      "\n",
      "Training with params:                                                                                                      \n",
      "{'booster': 'gbtree', 'eval_metric': 'auc', 'learning_rate': 1.0, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 17}\n",
      "\tScore 0.5867322318237038                                                                                                  \n",
      "\n",
      "\n",
      "Training with params:                                                                                                      \n",
      "{'booster': 'gbtree', 'eval_metric': 'auc', 'learning_rate': 1.0, 'nthread': 4, 'objective': 'binary:logistic', 'seed': 17}\n",
      " 10%|                                         | 25/250 [11:05:07<99:32:26, 1592.65s/it, best loss: 0.4132677681762962]"
     ]
    }
   ],
   "source": [
    "best_hyperparams = optimize(\n",
    "                            #trials\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:wpm_matching_py373]",
   "language": "python",
   "name": "conda-env-wpm_matching_py373-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
